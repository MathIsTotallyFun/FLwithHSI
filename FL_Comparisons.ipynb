{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-WaibHiwZQu"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Federated Learning Comparison: Neural Network, SVM, and Logistic Regression\n",
        "# =============================================================================\n",
        "# This notebook compares three machine learning approaches using federated learning\n",
        "# for disease classification based on spectral data\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning Comparison Study\n",
        "\n",
        "This notebook implements and compares three different machine learning approaches using federated learning:\n",
        "\n",
        "1. **Neural Network (NN)** - Deep learning approach with fully connected layers\n",
        "2. **Support Vector Machine (SVM)** - Linear classifier with hinge loss\n",
        "3. **Logistic Regression (LR)** - Linear classifier with logistic loss\n",
        "\n",
        "All models are trained using various federated learning strategies including FedAvg, FedProx, and FedAdam.\n",
        "\n",
        "## Dataset\n",
        "The dataset contains spectral data for disease classification with:\n",
        "- Features: Spectral measurements (300 dimensions)\n",
        "- Labels: Binary classification (diseased vs healthy)\n",
        "- Partitioned across 5 federated clients\n",
        "\n",
        "## Setup and Dependencies"
      ],
      "metadata": {
        "id": "Hw7CeLTYwcbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q flwr[simulation]\n",
        "\n",
        "# Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import flwr as fl\n",
        "from flwr.client import NumPyClient, Client, ClientApp\n",
        "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr.server.strategy import FedAvg, FedProx, FedAdam, FedOpt\n",
        "from flwr.common import Context, Parameters, ndarrays_to_parameters, parameters_to_ndarrays\n",
        "from scipy.interpolate import BSpline, make_lsq_spline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "id": "A-en3b_nwmqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "Upload your CSV files containing the spectral data. The files should be named with 'diseased' or 'healthy' to automatically assign labels."
      ],
      "metadata": {
        "id": "ph9OZzvmwqX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload data files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Process uploaded files and combine data\n",
        "print(\"Processing uploaded files...\")\n",
        "all_data = []\n",
        "\n",
        "for file in uploaded:\n",
        "    # Read and transpose the data (assuming first row contains column names)\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    df = df.T\n",
        "    df.columns = df.iloc[0]\n",
        "    df = df.drop(df.index[0])\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    print(f\"{file}: shape = {df.shape}\")\n",
        "\n",
        "    # Assign labels based on filename\n",
        "    label = 1 if \"diseased\" in file.lower() else 0\n",
        "    df[\"label\"] = label\n",
        "    all_data.append(df)\n",
        "\n",
        "# Combine all datasets\n",
        "df_all = pd.concat(all_data, ignore_index=True)\n",
        "print(f\"\\nCombined dataset shape: {df_all.shape}\")\n",
        "\n",
        "# Extract features and labels\n",
        "feature_cols = df_all.columns[2:-1]  # Remove ID columns and label\n",
        "X = df_all[feature_cols].values  # Features (N, 300)\n",
        "y = df_all['label'].values       # Labels (N,)\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Labels shape: {y.shape}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")"
      ],
      "metadata": {
        "id": "Oc0vv60-wv-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration and Utility Functions\n",
        "\n",
        "This section defines the configuration parameters and utility functions that will be used across all three federated learning approaches."
      ],
      "metadata": {
        "id": "Gh94tbWQw67K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION PARAMETERS\n",
        "# =============================================================================\n",
        "\n",
        "# Federated Learning Configuration\n",
        "NUM_PARTITIONS = 5      # Number of federated clients\n",
        "NUM_FOLDS = 20          # Number of cross-validation folds\n",
        "NUM_ROUNDS = 10        # Number of federated learning rounds\n",
        "\n",
        "# Model-specific parameters\n",
        "NN_EPOCHS = 5          # Local epochs for Neural Network\n",
        "NN_BATCH_SIZE = 32     # Batch size for Neural Network\n",
        "NN_LEARNING_RATE = 0.001\n",
        "\n",
        "# Model-specific strategy configurations\n",
        "model_strategies = {\n",
        "    'nn': {\n",
        "        \"FedAvg\": {\"no_values\": [0]},\n",
        "        \"FedProx\": {\"mu_values\": [0.01, 0.1, 1.0]},\n",
        "        \"FedAdam\": {\"eta_values\": [0.005, 0.01, 0.05, 0.1]},\n",
        "        \"FedOpt\": {\"eta_values\": [0.005, 0.01, 0.05, 0.1]},\n",
        "    },\n",
        "    'svm': {\n",
        "        \"FedAvg\": {\"no_values\": [0]},\n",
        "        \"FedProx\": {\"mu_values\": [0.01, 0.1, 1.0]},\n",
        "        \"FedAdam\": {\"eta_values\": [0.1, 0.5, 2.0, 5.0]},\n",
        "        \"FedOpt\": {\"eta_values\": [0.1, 0.5, 2.0, 5.0]},\n",
        "    },\n",
        "    'lr': {\n",
        "        \"FedAvg\": {\"no_values\": [0]},\n",
        "    \"FedProx\": {\"mu_values\": [0.01, 0.1, 1.0]},\n",
        "    \"FedAdam\": {\"eta_values\": [1.0, 2.0, 3.0, 5.0]},\n",
        "    \"FedOpt\": {\"eta_values\": [0.1, 0.2, 0.5, 1.0]},\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_strategies_for_model(model_type):\n",
        "    \"\"\"Get strategies configuration for a specific model type\"\"\"\n",
        "    if model_type in model_strategies:\n",
        "        return model_strategies[model_type]\n",
        "    else:\n",
        "        # Fallback to default configuration\n",
        "        return {\n",
        "            \"FedAvg\": {\"no_values\": [0]},\n",
        "            \"FedProx\": {\"mu_values\": [0.1, 1.0]},\n",
        "            \"FedAdam\": {\"eta_values\": [0.01, 0.1]},\n",
        "            \"FedOpt\": {\"eta_values\": [0.01, 0.1]},\n",
        "        }\n",
        "\n",
        "print(f\"Configuration loaded:\")\n",
        "print(f\"- Clients: {NUM_PARTITIONS}\")\n",
        "print(f\"- Folds: {NUM_FOLDS}\")\n",
        "print(f\"- FL Rounds: {NUM_ROUNDS}\")\n",
        "for model_type, strategies in model_strategies.items():\n",
        "    print(f\"\\n{model_type.upper()} Model:\")\n",
        "    for strategy_name, params in strategies.items():\n",
        "        param_type = list(params.keys())[0]\n",
        "        param_values = list(params.values())[0]\n",
        "        print(f\"  {strategy_name}: {param_type} = {param_values}\")"
      ],
      "metadata": {
        "id": "ZX1yWUtgxHZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILITY FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_model_sklearn(model, X, y):\n",
        "    \"\"\"Evaluate sklearn model and return comprehensive metrics\"\"\"\n",
        "    try:\n",
        "        # Get predictions\n",
        "        y_pred = model.predict(X)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y, y_pred)\n",
        "        precision = precision_score(y, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in evaluation: {e}\")\n",
        "        return {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
        "\n",
        "def train_model_sklearn(model, X, y):\n",
        "    \"\"\"Train sklearn model with error handling\"\"\"\n",
        "    try:\n",
        "        model.fit(X, y)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Training error: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_parameters_sklearn(model):\n",
        "    \"\"\"Extract parameters from sklearn model\"\"\"\n",
        "    if hasattr(model, 'coef_') and hasattr(model, 'intercept_'):\n",
        "        return [model.coef_.flatten(), model.intercept_.flatten()]\n",
        "    else:\n",
        "        # For untrained models, return zeros\n",
        "        return [np.zeros(300), np.zeros(1)]\n",
        "\n",
        "def set_parameters_sklearn(model, parameters):\n",
        "    \"\"\"Set parameters for sklearn model\"\"\"\n",
        "    if len(parameters) == 2:\n",
        "        model.coef_ = parameters[0].reshape(1, -1)\n",
        "        model.intercept_ = parameters[1]\n",
        "        model.classes_ = np.array([0, 1])  # Binary classification\n",
        "\n",
        "def compute_knot_vector(num_basis, spline_order):\n",
        "    num_total_knots = num_basis + spline_order + 1\n",
        "    num_internal_knots = num_total_knots - 2 * (spline_order + 1)\n",
        "    internal_knots = np.linspace(0, 1, num_internal_knots + 2)[1:-1]\n",
        "    t = np.concatenate((\n",
        "        np.repeat(0.0, spline_order + 1),\n",
        "        internal_knots,\n",
        "        np.repeat(1.0, spline_order + 1)\n",
        "    ))\n",
        "    return t\n",
        "\n",
        "def create_spline_features(X, num_basis=10, spline_order=3):\n",
        "    N, D = X.shape\n",
        "    x_domain = np.linspace(0, 1, D)\n",
        "    t = compute_knot_vector(num_basis, spline_order)\n",
        "    coeffs = np.zeros((N, num_basis))\n",
        "    for i in range(N):\n",
        "        y = X[i]\n",
        "        spline = make_lsq_spline(x_domain, y, t, spline_order)\n",
        "        coeffs[i] = spline.c\n",
        "    return coeffs\n",
        "\n",
        "def configure_model_hyperparameters(model_type, custom_config=None):\n",
        "    \"\"\"\n",
        "    Configure hyperparameters for a specific model type\n",
        "\n",
        "    Args:\n",
        "        model_type: 'nn', 'svm', or 'lr'\n",
        "        custom_config: Optional dictionary to override default values\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of strategies with model-specific hyperparameters\n",
        "    \"\"\"\n",
        "\n",
        "    # Get default configuration for the model\n",
        "    default_config = get_strategies_for_model(model_type)\n",
        "\n",
        "    # If custom configuration provided, merge it\n",
        "    if custom_config:\n",
        "        for strategy_name, params in custom_config.items():\n",
        "            if strategy_name in default_config:\n",
        "                default_config[strategy_name].update(params)\n",
        "            else:\n",
        "                default_config[strategy_name] = params\n",
        "\n",
        "    return default_config\n",
        "\n",
        "print(\"Utility functions defined successfully!\")"
      ],
      "metadata": {
        "id": "TpURFAECxIbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Partitioning for Federated Learning\n",
        "\n",
        "The data is partitioned into federated clients with preprocessing steps including:\n",
        "- Train/test split with stratification\n",
        "- Standardization using StandardScaler\n",
        "- B-spline feature engineering\n",
        "- Distribution across federated clients"
      ],
      "metadata": {
        "id": "ZtNIBPm8xh7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DATA PARTITIONING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def create_federated_data_partitions(X, y, fold_idx=0, apply_splines=True):\n",
        "    \"\"\"\n",
        "    Create federated data partitions for a specific fold\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        fold_idx: Current fold index for reproducible splits\n",
        "        apply_splines: Whether to apply B-spline preprocessing\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing partitioned data for each client\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nCreating federated partitions for fold {fold_idx + 1}...\")\n",
        "\n",
        "    # Split data into train and test\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, shuffle=True, random_state=fold_idx\n",
        "    )\n",
        "\n",
        "    print(f\"Train size: {X_train_raw.shape[0]}, Test size: {X_test_raw.shape[0]}\")\n",
        "\n",
        "    # Partition training data across clients\n",
        "    X_train_partitions_raw = np.array_split(X_train_raw, NUM_PARTITIONS)\n",
        "    y_train_partitions = np.array_split(y_train, NUM_PARTITIONS)\n",
        "    X_test_partitions_raw = np.array_split(X_test_raw, NUM_PARTITIONS)\n",
        "    y_test_partitions = np.array_split(y_test, NUM_PARTITIONS)\n",
        "\n",
        "    # Initialize data containers\n",
        "    client_train_data = []\n",
        "    client_val_data = []\n",
        "\n",
        "    # Process each client's data\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        print(f\"Processing client {cid + 1}/{NUM_PARTITIONS}...\")\n",
        "\n",
        "        # Get raw data for this client\n",
        "        X_train_client_raw = X_train_partitions_raw[cid]\n",
        "        y_train_client = y_train_partitions[cid]\n",
        "        X_test_client_raw = X_test_partitions_raw[cid]\n",
        "        y_test_client = y_test_partitions[cid]\n",
        "\n",
        "        # Apply B-spline preprocessing if requested\n",
        "        if apply_splines:\n",
        "            try:\n",
        "                X_train_client_processed = create_spline_features(X_train_client_raw)\n",
        "                X_test_client_processed = create_spline_features(X_test_client_raw)\n",
        "            except:\n",
        "                print(f\"Spline processing failed for client {cid}, using raw features\")\n",
        "                X_train_client_processed = X_train_client_raw\n",
        "                X_test_client_processed = X_test_client_raw\n",
        "        else:\n",
        "            X_train_client_processed = X_train_client_raw\n",
        "            X_test_client_processed = X_test_client_raw\n",
        "\n",
        "        # Standardize features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_client_scaled = scaler.fit_transform(X_train_client_processed)\n",
        "        X_test_client_scaled = scaler.transform(X_test_client_processed)\n",
        "\n",
        "        # Store processed data\n",
        "        client_train_data.append((X_train_client_scaled, y_train_client))\n",
        "        client_val_data.append((X_test_client_scaled, y_test_client))\n",
        "\n",
        "        print(f\"Client {cid + 1} - Train: {X_train_client_scaled.shape}, Test: {X_test_client_scaled.shape}\")\n",
        "\n",
        "    # Create centralized data for comparison\n",
        "    scaler_central = StandardScaler()\n",
        "    if apply_splines:\n",
        "        X_train_central = create_spline_features(X_train_raw)\n",
        "        X_test_central = create_spline_features(X_test_raw)\n",
        "    else:\n",
        "        X_train_central = X_train_raw\n",
        "        X_test_central = X_test_raw\n",
        "\n",
        "    X_train_scaled_central = scaler_central.fit_transform(X_train_central)\n",
        "    X_test_scaled_central = scaler_central.transform(X_test_central)\n",
        "\n",
        "    return {\n",
        "        'client_train_data': client_train_data,\n",
        "        'client_val_data': client_val_data,\n",
        "        'centralized_train': (X_train_scaled_central, y_train),\n",
        "        'centralized_test': (X_test_scaled_central, y_test),\n",
        "        'input_dim': X_train_client_scaled.shape[1]\n",
        "    }\n",
        "\n",
        "print(\"Data partitioning function ready!\")"
      ],
      "metadata": {
        "id": "suPr-seXxkY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Implementation\n",
        "\n",
        "This section implements a simple feedforward neural network for binary classification with PyTorch, including:\n",
        "- Network architecture definition\n",
        "- Training and evaluation functions\n",
        "- Federated learning client implementation\n",
        "- Parameter serialization for FL communication"
      ],
      "metadata": {
        "id": "u3cZhNUpxmLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NEURAL NETWORK MODEL DEFINITION\n",
        "# =============================================================================\n",
        "\n",
        "def get_device():\n",
        "    \"\"\"Get available device, with fallback to CPU\"\"\"\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            return torch.device(\"cuda\")\n",
        "        else:\n",
        "            return torch.device(\"cpu\")\n",
        "    except:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "# Initialize device\n",
        "device = get_device()\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Only print CUDA info if CUDA is actually available\n",
        "if device.type == \"cuda\":\n",
        "    try:\n",
        "        print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    except:\n",
        "        print(\"CUDA device info not available\")\n",
        "\n",
        "print(\"Device handling setup complete!\")\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple feedforward neural network for binary classification\n",
        "    Architecture: Input -> Hidden(64) -> BatchNorm -> Dropout -> Hidden(32) -> Output(2)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)  # 2 classes for binary classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_parameters_nn(model):\n",
        "    \"\"\"Extract parameters from PyTorch model\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "def set_parameters_nn(model, parameters):\n",
        "    \"\"\"Set parameters for PyTorch model with proper device handling\"\"\"\n",
        "    # Get the device the model is on\n",
        "    model_device = next(model.parameters()).device\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = {k: torch.tensor(v, device=model_device) for k, v in params_dict}\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def train_nn(model, X_train, y_train, epochs=NN_EPOCHS, batch_size=NN_BATCH_SIZE):\n",
        "    \"\"\"Train Neural Network model with proper device handling\"\"\"\n",
        "    # Get device from model\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Make copies of arrays to ensure they are writable\n",
        "    X_train_copy = np.array(X_train, copy=True)\n",
        "    y_train_copy = np.array(y_train, copy=True)\n",
        "\n",
        "    # Convert to tensors and move to same device as model\n",
        "    X_tensor = torch.FloatTensor(X_train_copy).to(model_device)\n",
        "    y_tensor = torch.LongTensor(y_train_copy).to(model_device)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Define loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=NN_LEARNING_RATE)\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            # Data should already be on correct device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        total_loss += epoch_loss / len(dataloader)\n",
        "\n",
        "    return total_loss / epochs\n",
        "\n",
        "def evaluate_nn(model, X_test, y_test):\n",
        "    \"\"\"Evaluate Neural Network model with proper device handling\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Get device from model\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        X_tensor = torch.FloatTensor(X_test).to(model_device)\n",
        "        y_tensor = torch.LongTensor(y_test).to(model_device)\n",
        "\n",
        "        outputs = model(X_tensor)\n",
        "\n",
        "        # Get predictions from logits\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (predictions == y_tensor).float().mean().item()\n",
        "\n",
        "        # Convert to numpy for sklearn metrics\n",
        "        y_pred_np = predictions.cpu().numpy()\n",
        "        y_true_np = y_tensor.cpu().numpy()\n",
        "\n",
        "        precision = precision_score(y_true_np, y_pred_np, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_true_np, y_pred_np, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_true_np, y_pred_np, average='weighted', zero_division=0)\n",
        "\n",
        "        # Calculate CrossEntropyLoss\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(outputs, y_tensor).item()\n",
        "\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "print(\"Neural Network functions defined successfully!\")"
      ],
      "metadata": {
        "id": "oNbY03AYxyn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NEURAL NETWORK FEDERATED CLIENT\n",
        "# =============================================================================\n",
        "\n",
        "class NeuralNetworkClient(fl.client.NumPyClient):\n",
        "    \"\"\"Federated Learning Client for Neural Network with CUDA support\"\"\"\n",
        "\n",
        "    def __init__(self, cid, X_train, y_train, X_val, y_val, input_dim):\n",
        "        self.cid = cid\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.model = SimpleNN(input_dim)\n",
        "\n",
        "        # Get available device in this process\n",
        "        try:\n",
        "            if torch.cuda.is_available():\n",
        "                self.device = torch.device(\"cuda\")\n",
        "            else:\n",
        "                self.device = torch.device(\"cpu\")\n",
        "        except:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "\n",
        "        # Move model to device\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        \"\"\"Get model parameters\"\"\"\n",
        "        return get_parameters_nn(self.model)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"Set model parameters\"\"\"\n",
        "        set_parameters_nn(self.model, parameters)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"Train the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Train the model\n",
        "        loss = train_nn(self.model, self.X_train, self.y_train)\n",
        "\n",
        "        # Return updated parameters and training info\n",
        "        return self.get_parameters(config), len(self.X_train), {\"loss\": loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        \"\"\"Evaluate the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Evaluate the model\n",
        "        metrics = evaluate_nn(self.model, self.X_val, self.y_val)\n",
        "\n",
        "        return metrics[\"loss\"], len(self.X_val), {\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"precision\": metrics[\"precision\"],\n",
        "            \"recall\": metrics[\"recall\"],\n",
        "            \"f1\": metrics[\"f1\"]\n",
        "        }\n",
        "\n",
        "def create_nn_client_fn(client_train_data, client_val_data, input_dim):\n",
        "    \"\"\"Create client function for Neural Network\"\"\"\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        cid_int = int(cid)\n",
        "        X_train, y_train = client_train_data[cid_int]\n",
        "        X_val, y_val = client_val_data[cid_int]\n",
        "\n",
        "        return NeuralNetworkClient(cid_int, X_train, y_train, X_val, y_val, input_dim)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "print(\"Neural Network federated client defined successfully!\")"
      ],
      "metadata": {
        "id": "PR1sbFE1yKKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Federated Training Function\n",
        "\n",
        "This function orchestrates the federated training process for the Neural Network approach, including:\n",
        "- Strategy configuration (FedAvg, FedProx, FedOpt, FedAdam)\n",
        "- Server-side evaluation\n",
        "- Result collection and processing"
      ],
      "metadata": {
        "id": "hM68WC3QyLGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# NEURAL NETWORK FEDERATED TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def run_nn_federated_learning(client_train_data, client_val_data, input_dim,\n",
        "                             strategy_name, param_value, param_type):\n",
        "    \"\"\"\n",
        "    Run federated learning with Neural Network\n",
        "\n",
        "    Args:\n",
        "        client_train_data: Training data for each client\n",
        "        client_val_data: Validation data for each client\n",
        "        input_dim: Input dimension for the model\n",
        "        strategy_name: FL strategy name\n",
        "        param_value: Strategy parameter value\n",
        "        param_type: Parameter type (mu, eta, or None)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing final metrics\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running NN FL with {strategy_name} ({param_type}={param_value})\")\n",
        "\n",
        "    # Create dummy model for initial parameters\n",
        "    dummy_model = SimpleNN(input_dim)\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            dummy_device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            dummy_device = torch.device(\"cpu\")\n",
        "    except:\n",
        "        dummy_device = torch.device(\"cpu\")\n",
        "\n",
        "    dummy_model = dummy_model.to(dummy_device)\n",
        "    initial_parameters = get_parameters_nn(dummy_model)\n",
        "\n",
        "    # Store results using shared state\n",
        "    shared_state = {\"final_metrics\": None, \"final_parameters\": None}\n",
        "\n",
        "    def get_evaluate_fn():\n",
        "        \"\"\"Create server-side evaluation function\"\"\"\n",
        "        def evaluate(server_round, parameters, config):\n",
        "            # Evaluate on all clients\n",
        "            all_metrics = []\n",
        "            for cid in range(NUM_PARTITIONS):\n",
        "                model = SimpleNN(input_dim)\n",
        "\n",
        "                # Get available device\n",
        "                try:\n",
        "                    if torch.cuda.is_available():\n",
        "                        eval_device = torch.device(\"cuda\")\n",
        "                    else:\n",
        "                        eval_device = torch.device(\"cpu\")\n",
        "                except:\n",
        "                    eval_device = torch.device(\"cpu\")\n",
        "\n",
        "                model = model.to(eval_device)\n",
        "                set_parameters_nn(model, parameters)\n",
        "                X_val, y_val = client_val_data[cid]\n",
        "                metrics = evaluate_nn(model, X_val, y_val)\n",
        "                all_metrics.append(metrics)\n",
        "\n",
        "            # Average metrics across clients\n",
        "            avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n",
        "\n",
        "            # Store final results\n",
        "            if server_round == NUM_ROUNDS:\n",
        "                shared_state[\"final_metrics\"] = avg_metrics.copy()\n",
        "                shared_state[\"final_parameters\"] = parameters\n",
        "\n",
        "            return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "\n",
        "        return evaluate\n",
        "\n",
        "    # Client function using new API\n",
        "    def client_fn(context: Context) -> Client:\n",
        "        partition_id = context.node_config[\"partition-id\"]\n",
        "        X_train, y_train = client_train_data[partition_id]\n",
        "        X_val, y_val = client_val_data[partition_id]\n",
        "\n",
        "        numpy_client = NeuralNetworkClient(partition_id, X_train, y_train, X_val, y_val, input_dim)\n",
        "        return numpy_client.to_client()\n",
        "\n",
        "    # Server function using new API\n",
        "    def server_fn(context: Context) -> ServerAppComponents:\n",
        "        # Configure strategy\n",
        "        if strategy_name == \"FedAvg\":\n",
        "            strategy = FedAvg(\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedProx\":\n",
        "            strategy = FedProx(\n",
        "                proximal_mu=param_value,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedAdam\":\n",
        "            strategy = FedAdam(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedOpt\":\n",
        "            strategy = FedOpt(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown strategy: {strategy_name}\")\n",
        "\n",
        "        return ServerAppComponents(config=ServerConfig(num_rounds=NUM_ROUNDS), strategy=strategy)\n",
        "\n",
        "    # Create client and server apps\n",
        "    client = ClientApp(client_fn=client_fn)\n",
        "    server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "    # Run federated learning simulation\n",
        "    try:\n",
        "        run_simulation(\n",
        "            client_app=client,\n",
        "            server_app=server,\n",
        "            num_supernodes=NUM_PARTITIONS,\n",
        "            backend_config={\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0.0}},\n",
        "        )\n",
        "\n",
        "        return shared_state[\"final_metrics\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in NN federated learning: {e}\")\n",
        "        return {\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0, \"loss\": float('inf')}\n",
        "\n",
        "print(\"Neural Network federated training function ready!\")"
      ],
      "metadata": {
        "id": "ylz317jLyNTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine Implementation\n",
        "\n",
        "This section implements Support Vector Machine (SVM) with hinge loss for binary classification using scikit-learn, including:\n",
        "- SVM model initialization and training\n",
        "- Parameter serialization for federated learning\n",
        "- Federated learning client implementation\n",
        "- Integration with FL strategies"
      ],
      "metadata": {
        "id": "VEZaLGKbyQk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SVM MODEL DEFINITION AND UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def initialize_svm_model(n_features):\n",
        "    \"\"\"\n",
        "    Initialize SVM model with hinge loss\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of input features\n",
        "\n",
        "    Returns:\n",
        "        Initialized SGDClassifier with SVM configuration\n",
        "    \"\"\"\n",
        "    model = SGDClassifier(\n",
        "        loss=\"hinge\",           # SVM hinge loss\n",
        "        max_iter=20,           # Local iterations\n",
        "        tol=None,              # No tolerance for early stopping\n",
        "        warm_start=True,       # Continue training from previous state\n",
        "        learning_rate=\"optimal\", # Optimal learning rate\n",
        "        eta0=0.01,             # Initial learning rate\n",
        "        random_state=42,       # For reproducibility\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def initialize_svm_model_centralized(n_features):\n",
        "    \"\"\"Initialize SVM model with 200 iterations for centralized/local training\"\"\"\n",
        "    model = SGDClassifier(\n",
        "        loss=\"hinge\",           # SVM hinge loss\n",
        "        max_iter=200,          # 200 iterations for centralized/local\n",
        "        tol=None,              # No tolerance for early stopping\n",
        "        warm_start=True,       # Continue training from previous state\n",
        "        learning_rate=\"optimal\", # Optimal learning rate\n",
        "        eta0=0.01,             # Initial learning rate\n",
        "        random_state=42,       # For reproducibility\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_parameters_svm(model):\n",
        "    \"\"\"Extract parameters from SVM model\"\"\"\n",
        "    if hasattr(model, 'coef_') and hasattr(model, 'intercept_'):\n",
        "        return [model.coef_.flatten(), model.intercept_.flatten()]\n",
        "    else:\n",
        "        # For untrained models, return zeros\n",
        "        return [np.zeros(300), np.zeros(1)]  # Assuming 300 features\n",
        "\n",
        "def set_parameters_svm(model, parameters):\n",
        "    \"\"\"Set parameters for SVM model\"\"\"\n",
        "    if len(parameters) >= 2:\n",
        "        model.coef_ = parameters[0].reshape(1, -1)\n",
        "        model.intercept_ = parameters[1]\n",
        "        model.classes_ = np.array([0, 1])  # Binary classification\n",
        "        # Mark as fitted\n",
        "        model._expanded_class_weight = [1.0, 1.0]\n",
        "        model.n_features_in_ = len(parameters[0])\n",
        "\n",
        "def train_svm(model, X_train, y_train):\n",
        "    \"\"\"Train SVM model with error handling\"\"\"\n",
        "    try:\n",
        "        # Ensure model is properly initialized\n",
        "        if not hasattr(model, 'classes_'):\n",
        "            model.partial_fit(X_train[:2], y_train[:2], classes=[0, 1])\n",
        "\n",
        "        # Continue training\n",
        "        model.partial_fit(X_train, y_train)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"SVM training error: {e}\")\n",
        "        return False\n",
        "\n",
        "def evaluate_svm(model, X_test, y_test):\n",
        "    \"\"\"Evaluate SVM model with comprehensive metrics\"\"\"\n",
        "    try:\n",
        "        # Get predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        # Calculate hinge loss\n",
        "        try:\n",
        "            decision_scores = model.decision_function(X_test)\n",
        "            # Manual hinge loss calculation\n",
        "            hinge_losses = np.maximum(0, 1 - y_test * decision_scores)\n",
        "            loss = np.mean(hinge_losses)\n",
        "        except:\n",
        "            loss = 1.0  # Default loss if calculation fails\n",
        "\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"SVM evaluation error: {e}\")\n",
        "        return {'loss': 1.0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
        "\n",
        "print(\"SVM utility functions defined successfully!\")"
      ],
      "metadata": {
        "id": "Bfhh8_dxyYdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SVM FEDERATED CLIENT\n",
        "# =============================================================================\n",
        "\n",
        "class SVMClient(fl.client.NumPyClient):\n",
        "    \"\"\"Federated Learning Client for SVM\"\"\"\n",
        "\n",
        "    def __init__(self, cid, X_train, y_train, X_val, y_val, input_dim):\n",
        "        self.cid = cid\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.model = initialize_svm_model(input_dim)\n",
        "\n",
        "        # Initialize model with a small batch to set up classes\n",
        "        if len(self.X_train) >= 2:\n",
        "            unique_classes = np.unique(self.y_train)\n",
        "            if len(unique_classes) >= 2:\n",
        "                # Find indices for each class\n",
        "                indices = []\n",
        "                for cls in [0, 1]:\n",
        "                    cls_indices = np.where(self.y_train == cls)[0]\n",
        "                    if len(cls_indices) > 0:\n",
        "                        indices.append(cls_indices[0])\n",
        "\n",
        "                if len(indices) >= 2:\n",
        "                    init_X = self.X_train[indices]\n",
        "                    init_y = self.y_train[indices]\n",
        "                    self.model.partial_fit(init_X, init_y, classes=[0, 1])\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        \"\"\"Get model parameters\"\"\"\n",
        "        return get_parameters_svm(self.model)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"Set model parameters\"\"\"\n",
        "        set_parameters_svm(self.model, parameters)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"Train the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Train the model\n",
        "        success = train_svm(self.model, self.X_train, self.y_train)\n",
        "\n",
        "        if success:\n",
        "            # Evaluate training loss\n",
        "            train_metrics = evaluate_svm(self.model, self.X_train, self.y_train)\n",
        "            loss = train_metrics[\"loss\"]\n",
        "        else:\n",
        "            loss = 1.0\n",
        "\n",
        "        return self.get_parameters(config), len(self.X_train), {\"loss\": loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        \"\"\"Evaluate the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Evaluate the model\n",
        "        metrics = evaluate_svm(self.model, self.X_val, self.y_val)\n",
        "\n",
        "        return metrics[\"loss\"], len(self.X_val), {\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"precision\": metrics[\"precision\"],\n",
        "            \"recall\": metrics[\"recall\"],\n",
        "            \"f1\": metrics[\"f1\"]\n",
        "        }\n",
        "\n",
        "def create_svm_client_fn(client_train_data, client_val_data, input_dim):\n",
        "    \"\"\"Create client function for SVM\"\"\"\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        cid_int = int(cid)\n",
        "        X_train, y_train = client_train_data[cid_int]\n",
        "        X_val, y_val = client_val_data[cid_int]\n",
        "\n",
        "        return SVMClient(cid_int, X_train, y_train, X_val, y_val, input_dim)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "print(\"SVM federated client defined successfully!\")"
      ],
      "metadata": {
        "id": "6X6Tg0uHyZtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM Federated Training Function\n",
        "\n",
        "This function handles the federated training process for SVM, including:\n",
        "- Strategy configuration with proper parameter initialization\n",
        "- Server-side model evaluation\n",
        "- Result aggregation across clients\n",
        "- Error handling for distributed training\n"
      ],
      "metadata": {
        "id": "lOZ0bYmNyeQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SVM FEDERATED TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def run_svm_federated_learning(client_train_data, client_val_data, input_dim,\n",
        "                              strategy_name, param_value, param_type):\n",
        "    \"\"\"\n",
        "    Run federated learning with SVM\n",
        "\n",
        "    Args:\n",
        "        client_train_data: Training data for each client\n",
        "        client_val_data: Validation data for each client\n",
        "        input_dim: Input dimension for the model\n",
        "        strategy_name: FL strategy name\n",
        "        param_value: Strategy parameter value\n",
        "        param_type: Parameter type (mu, eta, or None)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing final metrics\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running SVM FL with {strategy_name} ({param_type}={param_value})\")\n",
        "\n",
        "    # Create dummy model for initial parameters\n",
        "    dummy_model = initialize_svm_model(input_dim)\n",
        "\n",
        "    # Initialize with some sample data\n",
        "    if len(client_train_data) > 0:\n",
        "        X_init, y_init = client_train_data[0]\n",
        "        if len(X_init) >= 2:\n",
        "            init_samples = min(5, len(X_init))\n",
        "            dummy_model.partial_fit(X_init[:init_samples], y_init[:init_samples], classes=[0, 1])\n",
        "\n",
        "    initial_parameters = get_parameters_svm(dummy_model)\n",
        "\n",
        "    # Store results using shared state\n",
        "    shared_state = {\"final_metrics\": None, \"final_parameters\": None}\n",
        "\n",
        "    def get_evaluate_fn():\n",
        "        \"\"\"Create server-side evaluation function\"\"\"\n",
        "        def evaluate(server_round, parameters, config):\n",
        "            # Evaluate on all clients\n",
        "            all_metrics = []\n",
        "            for cid in range(NUM_PARTITIONS):\n",
        "                model = initialize_svm_model(input_dim)\n",
        "                set_parameters_svm(model, parameters)\n",
        "                X_val, y_val = client_val_data[cid]\n",
        "                metrics = evaluate_svm(model, X_val, y_val)\n",
        "                all_metrics.append(metrics)\n",
        "\n",
        "            # Average metrics across clients\n",
        "            avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n",
        "\n",
        "            # Store final results\n",
        "            if server_round == NUM_ROUNDS:\n",
        "                shared_state[\"final_metrics\"] = avg_metrics.copy()\n",
        "                shared_state[\"final_parameters\"] = parameters\n",
        "\n",
        "            return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "\n",
        "        return evaluate\n",
        "\n",
        "    # Client function using new API\n",
        "    def client_fn(context: Context) -> Client:\n",
        "        partition_id = context.node_config[\"partition-id\"]\n",
        "        X_train, y_train = client_train_data[partition_id]\n",
        "        X_val, y_val = client_val_data[partition_id]\n",
        "\n",
        "        numpy_client = SVMClient(partition_id, X_train, y_train, X_val, y_val, input_dim)\n",
        "        return numpy_client.to_client()\n",
        "\n",
        "    # Server function using new API\n",
        "    def server_fn(context: Context) -> ServerAppComponents:\n",
        "        # Configure strategy\n",
        "        if strategy_name == \"FedAvg\":\n",
        "            strategy = FedAvg(\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedProx\":\n",
        "            strategy = FedProx(\n",
        "                proximal_mu=param_value,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedAdam\":\n",
        "            strategy = FedAdam(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedOpt\":\n",
        "            strategy = FedOpt(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown strategy: {strategy_name}\")\n",
        "\n",
        "        return ServerAppComponents(config=ServerConfig(num_rounds=NUM_ROUNDS), strategy=strategy)\n",
        "\n",
        "    # Create client and server apps\n",
        "    client = ClientApp(client_fn=client_fn)\n",
        "    server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "    # Run federated learning simulation\n",
        "    try:\n",
        "        run_simulation(\n",
        "            client_app=client,\n",
        "            server_app=server,\n",
        "            num_supernodes=NUM_PARTITIONS,\n",
        "            backend_config={\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0.0}},\n",
        "        )\n",
        "\n",
        "        return shared_state[\"final_metrics\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in SVM federated learning: {e}\")\n",
        "        return {\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0, \"loss\": float('inf')}\n",
        "\n",
        "print(\"SVM federated training function ready!\")"
      ],
      "metadata": {
        "id": "bE0J_8xMyfvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Implementation\n",
        "\n",
        "This section implements Logistic Regression for binary classification using scikit-learn's SGDClassifier with log loss, including:\n",
        "- Logistic regression model initialization and training\n",
        "- Parameter management for federated learning\n",
        "- Federated learning client implementation\n",
        "- Integration with various FL strategies"
      ],
      "metadata": {
        "id": "gvJMB3N9yhOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LOGISTIC REGRESSION MODEL DEFINITION AND UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def initialize_lr_model(n_features):\n",
        "    \"\"\"\n",
        "    Initialize Logistic Regression model with log loss\n",
        "\n",
        "    Args:\n",
        "        n_features: Number of input features\n",
        "\n",
        "    Returns:\n",
        "        Initialized SGDClassifier with Logistic Regression configuration\n",
        "    \"\"\"\n",
        "    model = SGDClassifier(\n",
        "        loss=\"log_loss\",        # Logistic regression loss\n",
        "        max_iter=20,           # Local iterations\n",
        "        tol=None,              # No tolerance for early stopping\n",
        "        warm_start=True,       # Continue training from previous state\n",
        "        learning_rate=\"optimal\", # Optimal learning rate\n",
        "        eta0=0.01,             # Initial learning rate\n",
        "        random_state=42,       # For reproducibility\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def initialize_lr_model_centralized(n_features):\n",
        "    \"\"\"Initialize Logistic Regression model with 200 iterations for centralized/local training\"\"\"\n",
        "    model = SGDClassifier(\n",
        "        loss=\"log_loss\",        # Logistic regression loss\n",
        "        max_iter=200,          # 200 iterations for centralized/local\n",
        "        tol=None,              # No tolerance for early stopping\n",
        "        warm_start=True,       # Continue training from previous state\n",
        "        learning_rate=\"optimal\", # Optimal learning rate\n",
        "        eta0=0.01,             # Initial learning rate\n",
        "        random_state=42,       # For reproducibility\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def get_parameters_lr(model):\n",
        "    \"\"\"Extract parameters from Logistic Regression model\"\"\"\n",
        "    if hasattr(model, 'coef_') and hasattr(model, 'intercept_'):\n",
        "        return [model.coef_.flatten(), model.intercept_.flatten()]\n",
        "    else:\n",
        "        # For untrained models, return zeros\n",
        "        return [np.zeros(300), np.zeros(1)]  # Assuming 300 features\n",
        "\n",
        "def set_parameters_lr(model, parameters):\n",
        "    \"\"\"Set parameters for Logistic Regression model\"\"\"\n",
        "    if len(parameters) >= 2:\n",
        "        model.coef_ = parameters[0].reshape(1, -1)\n",
        "        model.intercept_ = parameters[1]\n",
        "        model.classes_ = np.array([0, 1])  # Binary classification\n",
        "        # Mark as fitted\n",
        "        model._expanded_class_weight = [1.0, 1.0]\n",
        "        model.n_features_in_ = len(parameters[0])\n",
        "\n",
        "def train_lr(model, X_train, y_train):\n",
        "    \"\"\"Train Logistic Regression model with error handling\"\"\"\n",
        "    try:\n",
        "        # Ensure model is properly initialized\n",
        "        if not hasattr(model, 'classes_'):\n",
        "            model.partial_fit(X_train[:2], y_train[:2], classes=[0, 1])\n",
        "\n",
        "        # Continue training\n",
        "        model.partial_fit(X_train, y_train)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"LR training error: {e}\")\n",
        "        return False\n",
        "\n",
        "def evaluate_lr(model, X_test, y_test):\n",
        "    \"\"\"Evaluate Logistic Regression model with comprehensive metrics\"\"\"\n",
        "    try:\n",
        "        # Get predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        # Calculate log loss\n",
        "        try:\n",
        "            # Get probability predictions\n",
        "            y_proba = model.predict_proba(X_test)\n",
        "            # Calculate log loss manually to avoid sklearn warnings\n",
        "            epsilon = 1e-15  # Small value to avoid log(0)\n",
        "            y_proba = np.clip(y_proba, epsilon, 1 - epsilon)\n",
        "\n",
        "            # Convert y_test to one-hot for log loss calculation\n",
        "            n_classes = y_proba.shape[1]\n",
        "            y_one_hot = np.eye(n_classes)[y_test]\n",
        "\n",
        "            loss = -np.mean(np.sum(y_one_hot * np.log(y_proba), axis=1))\n",
        "        except:\n",
        "            loss = 1.0  # Default loss if calculation fails\n",
        "\n",
        "        return {\n",
        "            'loss': loss,\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"LR evaluation error: {e}\")\n",
        "        return {'loss': 1.0, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1': 0}\n",
        "\n",
        "print(\"Logistic Regression utility functions defined successfully!\")"
      ],
      "metadata": {
        "id": "oOyVzopbysxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LOGISTIC REGRESSION FEDERATED CLIENT\n",
        "# =============================================================================\n",
        "\n",
        "class LogisticRegressionClient(fl.client.NumPyClient):\n",
        "    \"\"\"Federated Learning Client for Logistic Regression\"\"\"\n",
        "\n",
        "    def __init__(self, cid, X_train, y_train, X_val, y_val, input_dim):\n",
        "        self.cid = cid\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.model = initialize_lr_model(input_dim)\n",
        "\n",
        "        # Initialize model with a small batch to set up classes\n",
        "        if len(self.X_train) >= 2:\n",
        "            unique_classes = np.unique(self.y_train)\n",
        "            if len(unique_classes) >= 2:\n",
        "                # Find indices for each class\n",
        "                indices = []\n",
        "                for cls in [0, 1]:\n",
        "                    cls_indices = np.where(self.y_train == cls)[0]\n",
        "                    if len(cls_indices) > 0:\n",
        "                        indices.append(cls_indices[0])\n",
        "\n",
        "                if len(indices) >= 2:\n",
        "                    init_X = self.X_train[indices]\n",
        "                    init_y = self.y_train[indices]\n",
        "                    self.model.partial_fit(init_X, init_y, classes=[0, 1])\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        \"\"\"Get model parameters\"\"\"\n",
        "        return get_parameters_lr(self.model)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"Set model parameters\"\"\"\n",
        "        set_parameters_lr(self.model, parameters)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"Train the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Train the model\n",
        "        success = train_lr(self.model, self.X_train, self.y_train)\n",
        "\n",
        "        if success:\n",
        "            # Evaluate training loss\n",
        "            train_metrics = evaluate_lr(self.model, self.X_train, self.y_train)\n",
        "            loss = train_metrics[\"loss\"]\n",
        "        else:\n",
        "            loss = 1.0\n",
        "\n",
        "        return self.get_parameters(config), len(self.X_train), {\"loss\": loss}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        \"\"\"Evaluate the model locally\"\"\"\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        # Evaluate the model\n",
        "        metrics = evaluate_lr(self.model, self.X_val, self.y_val)\n",
        "\n",
        "        return metrics[\"loss\"], len(self.X_val), {\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"precision\": metrics[\"precision\"],\n",
        "            \"recall\": metrics[\"recall\"],\n",
        "            \"f1\": metrics[\"f1\"]\n",
        "        }\n",
        "\n",
        "def create_lr_client_fn(client_train_data, client_val_data, input_dim):\n",
        "    \"\"\"Create client function for Logistic Regression\"\"\"\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        cid_int = int(cid)\n",
        "        X_train, y_train = client_train_data[cid_int]\n",
        "        X_val, y_val = client_val_data[cid_int]\n",
        "\n",
        "        return LogisticRegressionClient(cid_int, X_train, y_train, X_val, y_val, input_dim)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "print(\"Logistic Regression federated client defined successfully!\")"
      ],
      "metadata": {
        "id": "DYLraimXytyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression Federated Training Function\n",
        "\n",
        "This function orchestrates the federated training process for Logistic Regression, including:\n",
        "- Proper model initialization with sample data\n",
        "- Strategy configuration for different FL algorithms\n",
        "- Server-side evaluation and metrics aggregation\n",
        "- Robust error handling for distributed training"
      ],
      "metadata": {
        "id": "pSsGTemjyvDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# LOGISTIC REGRESSION FEDERATED TRAINING FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def run_lr_federated_learning(client_train_data, client_val_data, input_dim,\n",
        "                             strategy_name, param_value, param_type):\n",
        "    \"\"\"\n",
        "    Run federated learning with Logistic Regression\n",
        "\n",
        "    Args:\n",
        "        client_train_data: Training data for each client\n",
        "        client_val_data: Validation data for each client\n",
        "        input_dim: Input dimension for the model\n",
        "        strategy_name: FL strategy name\n",
        "        param_value: Strategy parameter value\n",
        "        param_type: Parameter type (mu, eta, or None)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing final metrics\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running LR FL with {strategy_name} ({param_type}={param_value})\")\n",
        "\n",
        "    # Create dummy model for initial parameters\n",
        "    dummy_model = initialize_lr_model(input_dim)\n",
        "\n",
        "    # Initialize with some sample data\n",
        "    if len(client_train_data) > 0:\n",
        "        X_init, y_init = client_train_data[0]\n",
        "        if len(X_init) >= 2:\n",
        "            init_samples = min(5, len(X_init))\n",
        "            dummy_model.partial_fit(X_init[:init_samples], y_init[:init_samples], classes=[0, 1])\n",
        "\n",
        "    initial_parameters = get_parameters_lr(dummy_model)\n",
        "\n",
        "    # Store results using shared state\n",
        "    shared_state = {\"final_metrics\": None, \"final_parameters\": None}\n",
        "\n",
        "    def get_evaluate_fn():\n",
        "        \"\"\"Create server-side evaluation function\"\"\"\n",
        "        def evaluate(server_round, parameters, config):\n",
        "            # Evaluate on all clients\n",
        "            all_metrics = []\n",
        "            for cid in range(NUM_PARTITIONS):\n",
        "                model = initialize_lr_model(input_dim)\n",
        "                set_parameters_lr(model, parameters)\n",
        "                X_val, y_val = client_val_data[cid]\n",
        "                metrics = evaluate_lr(model, X_val, y_val)\n",
        "                all_metrics.append(metrics)\n",
        "\n",
        "            # Average metrics across clients\n",
        "            avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n",
        "\n",
        "            # Store final results\n",
        "            if server_round == NUM_ROUNDS:\n",
        "                shared_state[\"final_metrics\"] = avg_metrics.copy()\n",
        "                shared_state[\"final_parameters\"] = parameters\n",
        "\n",
        "            return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "\n",
        "        return evaluate\n",
        "\n",
        "    # Client function using new API\n",
        "    def client_fn(context: Context) -> Client:\n",
        "        partition_id = context.node_config[\"partition-id\"]\n",
        "        X_train, y_train = client_train_data[partition_id]\n",
        "        X_val, y_val = client_val_data[partition_id]\n",
        "\n",
        "        numpy_client = LogisticRegressionClient(partition_id, X_train, y_train, X_val, y_val, input_dim)\n",
        "        return numpy_client.to_client()\n",
        "\n",
        "    # Server function using new API\n",
        "    def server_fn(context: Context) -> ServerAppComponents:\n",
        "        # Configure strategy\n",
        "        if strategy_name == \"FedAvg\":\n",
        "            strategy = FedAvg(\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedProx\":\n",
        "            strategy = FedProx(\n",
        "                proximal_mu=param_value,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedAdam\":\n",
        "            strategy = FedAdam(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        elif strategy_name == \"FedOpt\":\n",
        "            strategy = FedOpt(\n",
        "                initial_parameters=ndarrays_to_parameters(initial_parameters),\n",
        "                eta=param_value,\n",
        "                beta_1=0.9,\n",
        "                beta_2=0.99,\n",
        "                tau=1e-9,\n",
        "                min_available_clients=NUM_PARTITIONS,\n",
        "                evaluate_fn=get_evaluate_fn(),\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown strategy: {strategy_name}\")\n",
        "\n",
        "        return ServerAppComponents(config=ServerConfig(num_rounds=NUM_ROUNDS), strategy=strategy)\n",
        "\n",
        "    # Create client and server apps\n",
        "    client = ClientApp(client_fn=client_fn)\n",
        "    server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "    # Run federated learning simulation\n",
        "    try:\n",
        "        run_simulation(\n",
        "            client_app=client,\n",
        "            server_app=server,\n",
        "            num_supernodes=NUM_PARTITIONS,\n",
        "            backend_config={\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0.0}},\n",
        "        )\n",
        "\n",
        "        return shared_state[\"final_metrics\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in LR federated learning: {e}\")\n",
        "        return {\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0, \"loss\": float('inf')}\n",
        "\n",
        "print(\"Logistic Regression federated training function ready!\")"
      ],
      "metadata": {
        "id": "dbjPs1lVyx2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Experiment Framework\n",
        "\n",
        "This section orchestrates the complete federated learning comparison experiment, including:\n",
        "- Cross-validation setup with multiple folds\n",
        "- Federated learning experiments for all three approaches\n",
        "- Centralized and local training baselines\n",
        "- Results collection and analysis\n",
        "- Performance visualization and comparison"
      ],
      "metadata": {
        "id": "dvQDAnV1yyOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CENTRALIZED AND LOCAL TRAINING BASELINES\n",
        "# =============================================================================\n",
        "\n",
        "def run_centralized_training(X_train_central, y_train_central, X_test_central, y_test_central, model_type):\n",
        "    \"\"\"\n",
        "    Run centralized training for comparison baseline\n",
        "\n",
        "    Args:\n",
        "        X_train_central: Centralized training features\n",
        "        y_train_central: Centralized training labels\n",
        "        X_test_central: Centralized test features\n",
        "        y_test_central: Centralized test labels\n",
        "        model_type: Type of model ('nn', 'svm', 'lr')\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing evaluation metrics\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running centralized {model_type.upper()} training...\")\n",
        "\n",
        "    try:\n",
        "        if model_type == 'nn':\n",
        "            # Neural Network centralized training with proper device handling\n",
        "            model = SimpleNN(X_train_central.shape[1])\n",
        "\n",
        "            # Get available device\n",
        "            try:\n",
        "                if torch.cuda.is_available():\n",
        "                    model_device = torch.device(\"cuda\")\n",
        "                else:\n",
        "                    model_device = torch.device(\"cpu\")\n",
        "            except:\n",
        "                model_device = torch.device(\"cpu\")\n",
        "\n",
        "            model = model.to(model_device)\n",
        "            train_nn(model, X_train_central, y_train_central, epochs=NN_EPOCHS*10)\n",
        "            metrics = evaluate_nn(model, X_test_central, y_test_central)\n",
        "\n",
        "        elif model_type == 'svm':\n",
        "            # SVM centralized training (unchanged)\n",
        "            model = initialize_svm_model_centralized(X_train_central.shape[1])\n",
        "            model.fit(X_train_central, y_train_central)\n",
        "            metrics = evaluate_svm(model, X_test_central, y_test_central)\n",
        "\n",
        "        elif model_type == 'lr':\n",
        "            # Logistic Regression centralized training (unchanged)\n",
        "            model = initialize_lr_model_centralized(X_train_central.shape[1])\n",
        "            model.fit(X_train_central, y_train_central)\n",
        "            metrics = evaluate_lr(model, X_test_central, y_test_central)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in centralized {model_type} training: {e}\")\n",
        "        return {\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0, \"loss\": float('inf')}\n",
        "\n",
        "def run_local_training(client_train_data, client_val_data, model_type):\n",
        "    \"\"\"\n",
        "    Run local training on each client separately\n",
        "\n",
        "    Args:\n",
        "        client_train_data: Training data for each client\n",
        "        client_val_data: Validation data for each client\n",
        "        model_type: Type of model ('nn', 'svm', 'lr')\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing averaged evaluation metrics across clients\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Running local {model_type.upper()} training...\")\n",
        "\n",
        "    all_metrics = []\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        try:\n",
        "            X_train, y_train = client_train_data[cid]\n",
        "            X_val, y_val = client_val_data[cid]\n",
        "\n",
        "            if model_type == 'nn':\n",
        "                # Neural Network local training with proper device handling\n",
        "                model = SimpleNN(X_train.shape[1])\n",
        "\n",
        "                # Get available device\n",
        "                try:\n",
        "                    if torch.cuda.is_available():\n",
        "                        model_device = torch.device(\"cuda\")\n",
        "                    else:\n",
        "                        model_device = torch.device(\"cpu\")\n",
        "                except:\n",
        "                    model_device = torch.device(\"cpu\")\n",
        "\n",
        "                model = model.to(model_device)\n",
        "                train_nn(model, X_train, y_train, epochs=NN_EPOCHS*10)\n",
        "                metrics = evaluate_nn(model, X_val, y_val)\n",
        "\n",
        "            elif model_type == 'svm':\n",
        "                # SVM local training (unchanged)\n",
        "                model = initialize_svm_model_centralized(X_train.shape[1])\n",
        "                model.fit(X_train, y_train)\n",
        "                metrics = evaluate_svm(model, X_val, y_val)\n",
        "\n",
        "            elif model_type == 'lr':\n",
        "                # Logistic Regression local training (unchanged)\n",
        "                model = initialize_lr_model_centralized(X_train.shape[1])\n",
        "                model.fit(X_train, y_train)\n",
        "                metrics = evaluate_lr(model, X_val, y_val)\n",
        "\n",
        "            all_metrics.append(metrics)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in local {model_type} training for client {cid}: {e}\")\n",
        "            all_metrics.append({\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0, \"loss\": float('inf')})\n",
        "\n",
        "    # Average metrics across all clients\n",
        "    avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n",
        "    return avg_metrics\n",
        "\n",
        "print(\"Baseline training functions defined successfully!\")"
      ],
      "metadata": {
        "id": "dcq1jIB7y5Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN EXPERIMENT ORCHESTRATION\n",
        "# =============================================================================\n",
        "\n",
        "def run_complete_experiment(X, y, model_type='nn', apply_splines=True, custom_hyperparams=None):\n",
        "    \"\"\"\n",
        "    Run complete federated learning experiment with cross-validation\n",
        "\n",
        "    Args:\n",
        "        X: Feature matrix\n",
        "        y: Labels\n",
        "        model_type: Type of model ('nn', 'svm', 'lr')\n",
        "        apply_splines: Whether to apply B-spline preprocessing\n",
        "        custom_hyperparams: Optional custom hyperparameter configuration\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing all experimental results\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"STARTING COMPLETE EXPERIMENT: {model_type.upper()}\")\n",
        "\n",
        "    # Get model-specific strategies\n",
        "    strategies = configure_model_hyperparameters(model_type, custom_hyperparams)\n",
        "\n",
        "    print(f\"Model-specific strategies loaded:\")\n",
        "    for strategy_name, params in strategies.items():\n",
        "        param_type = list(params.keys())[0]\n",
        "        param_values = list(params.values())[0]\n",
        "        print(f\"  {strategy_name}: {param_type} = {param_values}\")\n",
        "\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Results storage\n",
        "    all_results = {\n",
        "        'federated': {},\n",
        "        'centralized': [],\n",
        "        'local': []\n",
        "    }\n",
        "\n",
        "    # Initialize federated results for each strategy\n",
        "    for strategy_name in strategies.keys():\n",
        "        all_results['federated'][strategy_name] = {}\n",
        "\n",
        "    # Cross-validation loop\n",
        "    for fold_idx in range(NUM_FOLDS):\n",
        "        print(f\"\\n--- FOLD {fold_idx + 1}/{NUM_FOLDS} ---\")\n",
        "\n",
        "        # Create federated data partitions\n",
        "        data_partitions = create_federated_data_partitions(X, y, fold_idx, apply_splines)\n",
        "\n",
        "        client_train_data = data_partitions['client_train_data']\n",
        "        client_val_data = data_partitions['client_val_data']\n",
        "        centralized_train = data_partitions['centralized_train']\n",
        "        centralized_test = data_partitions['centralized_test']\n",
        "        input_dim = data_partitions['input_dim']\n",
        "\n",
        "        # Run centralized training\n",
        "        print(\"Running centralized baseline...\")\n",
        "        centralized_metrics = run_centralized_training(\n",
        "            centralized_train[0], centralized_train[1],\n",
        "            centralized_test[0], centralized_test[1],\n",
        "            model_type\n",
        "        )\n",
        "        all_results['centralized'].append(centralized_metrics)\n",
        "\n",
        "        # Run local training\n",
        "        print(\"Running local baseline...\")\n",
        "        local_metrics = run_local_training(client_train_data, client_val_data, model_type)\n",
        "        all_results['local'].append(local_metrics)\n",
        "\n",
        "        # Run federated learning for each strategy\n",
        "        for strategy_name, params in strategies.items():\n",
        "            print(f\"\\nTesting {strategy_name}...\")\n",
        "\n",
        "            # Get parameter values for this strategy\n",
        "            if \"mu_values\" in params:\n",
        "                param_values = params[\"mu_values\"]\n",
        "                param_type = \"mu\"\n",
        "            elif \"eta_values\" in params:\n",
        "                param_values = params[\"eta_values\"]\n",
        "                param_type = \"eta\"\n",
        "            else:\n",
        "                param_values = params[\"no_values\"]\n",
        "                param_type = \"none\"\n",
        "\n",
        "            # Initialize results for this strategy if not exists\n",
        "            if strategy_name not in all_results['federated']:\n",
        "                all_results['federated'][strategy_name] = {}\n",
        "\n",
        "            # Test each parameter value\n",
        "            for param_value in param_values:\n",
        "                print(f\"  Testing {param_type}={param_value}\")\n",
        "\n",
        "                # Initialize results for this parameter if not exists\n",
        "                param_key = f\"{param_type}_{param_value}\"\n",
        "                if param_key not in all_results['federated'][strategy_name]:\n",
        "                    all_results['federated'][strategy_name][param_key] = []\n",
        "\n",
        "                # Run federated learning\n",
        "                if model_type == 'nn':\n",
        "                    fl_metrics = run_nn_federated_learning(\n",
        "                        client_train_data, client_val_data, input_dim,\n",
        "                        strategy_name, param_value, param_type\n",
        "                    )\n",
        "                elif model_type == 'svm':\n",
        "                    fl_metrics = run_svm_federated_learning(\n",
        "                        client_train_data, client_val_data, input_dim,\n",
        "                        strategy_name, param_value, param_type\n",
        "                    )\n",
        "                elif model_type == 'lr':\n",
        "                    fl_metrics = run_lr_federated_learning(\n",
        "                        client_train_data, client_val_data, input_dim,\n",
        "                        strategy_name, param_value, param_type\n",
        "                    )\n",
        "\n",
        "                all_results['federated'][strategy_name][param_key].append(fl_metrics)\n",
        "\n",
        "        print(f\"Fold {fold_idx + 1} completed!\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "print(\"Main experiment orchestration function ready!\")"
      ],
      "metadata": {
        "id": "htpjBR6xy9Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results Analysis and Visualization\n",
        "\n",
        "This section provides comprehensive analysis of the experimental results, including:\n",
        "- Statistical summary of performance metrics\n",
        "- Comparison across different FL strategies\n",
        "- Visualization of results with plots and tables\n",
        "- Best hyperparameter identification"
      ],
      "metadata": {
        "id": "e2CXb84ry_49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RESULTS ANALYSIS AND VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "def analyze_results(results, model_type):\n",
        "    \"\"\"\n",
        "    Analyze and summarize experimental results\n",
        "\n",
        "    Args:\n",
        "        results: Dictionary containing all experimental results\n",
        "        model_type: Type of model ('nn', 'svm', 'lr')\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing analysis summary\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"RESULTS ANALYSIS: {model_type.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    analysis = {\n",
        "        'summary_stats': {},\n",
        "        'best_configs': {},\n",
        "        'comparison_table': None\n",
        "    }\n",
        "\n",
        "    # Analyze centralized results\n",
        "    if results['centralized']:\n",
        "        centralized_df = pd.DataFrame(results['centralized'])\n",
        "        analysis['summary_stats']['centralized'] = {\n",
        "            'accuracy_mean': centralized_df['accuracy'].mean(),\n",
        "            'accuracy_std': centralized_df['accuracy'].std(),\n",
        "            'f1_mean': centralized_df['f1'].mean(),\n",
        "            'f1_std': centralized_df['f1'].std()\n",
        "        }\n",
        "        print(f\"Centralized - Accuracy: {centralized_df['accuracy'].mean():.4f} ± {centralized_df['accuracy'].std():.4f}\")\n",
        "        print(f\"Centralized - F1: {centralized_df['f1'].mean():.4f} ± {centralized_df['f1'].std():.4f}\")\n",
        "\n",
        "    # Analyze local results\n",
        "    if results['local']:\n",
        "        local_df = pd.DataFrame(results['local'])\n",
        "        analysis['summary_stats']['local'] = {\n",
        "            'accuracy_mean': local_df['accuracy'].mean(),\n",
        "            'accuracy_std': local_df['accuracy'].std(),\n",
        "            'f1_mean': local_df['f1'].mean(),\n",
        "            'f1_std': local_df['f1'].std()\n",
        "        }\n",
        "        print(f\"Local - Accuracy: {local_df['accuracy'].mean():.4f} ± {local_df['accuracy'].std():.4f}\")\n",
        "        print(f\"Local - F1: {local_df['f1'].mean():.4f} ± {local_df['f1'].std():.4f}\")\n",
        "\n",
        "    # Analyze federated results\n",
        "    print(f\"\\nFederated Learning Results:\")\n",
        "    best_accuracy = 0\n",
        "    best_config = None\n",
        "\n",
        "    for strategy_name, strategy_results in results['federated'].items():\n",
        "        print(f\"\\n{strategy_name}:\")\n",
        "        analysis['summary_stats'][strategy_name] = {}\n",
        "\n",
        "        for param_key, param_results in strategy_results.items():\n",
        "            if param_results:  # Check if results exist\n",
        "                param_df = pd.DataFrame(param_results)\n",
        "                acc_mean = param_df['accuracy'].mean()\n",
        "                acc_std = param_df['accuracy'].std()\n",
        "                f1_mean = param_df['f1'].mean()\n",
        "                f1_std = param_df['f1'].std()\n",
        "\n",
        "                analysis['summary_stats'][strategy_name][param_key] = {\n",
        "                    'accuracy_mean': acc_mean,\n",
        "                    'accuracy_std': acc_std,\n",
        "                    'f1_mean': f1_mean,\n",
        "                    'f1_std': f1_std\n",
        "                }\n",
        "\n",
        "                print(f\"  {param_key}: Acc={acc_mean:.4f}±{acc_std:.4f}, F1={f1_mean:.4f}±{f1_std:.4f}\")\n",
        "\n",
        "                # Track best configuration\n",
        "                if acc_mean > best_accuracy:\n",
        "                    best_accuracy = acc_mean\n",
        "                    best_config = f\"{strategy_name}_{param_key}\"\n",
        "\n",
        "    analysis['best_configs']['accuracy'] = best_config\n",
        "    print(f\"\\nBest FL Configuration: {best_config} (Accuracy: {best_accuracy:.4f})\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "def create_comparison_table(results, model_type):\n",
        "    \"\"\"Create a comparison table of all approaches\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PERFORMANCE COMPARISON TABLE: {model_type.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    comparison_data = []\n",
        "\n",
        "    # Add centralized results\n",
        "    if results['centralized']:\n",
        "        centralized_df = pd.DataFrame(results['centralized'])\n",
        "        comparison_data.append({\n",
        "            'Approach': 'Centralized',\n",
        "            'Strategy': 'N/A',\n",
        "            'Parameter': 'N/A',\n",
        "            'Accuracy': f\"{centralized_df['accuracy'].mean():.4f} ± {centralized_df['accuracy'].std():.4f}\",\n",
        "            'F1': f\"{centralized_df['f1'].mean():.4f} ± {centralized_df['f1'].std():.4f}\",\n",
        "            'Precision': f\"{centralized_df['precision'].mean():.4f} ± {centralized_df['precision'].std():.4f}\",\n",
        "            'Recall': f\"{centralized_df['recall'].mean():.4f} ± {centralized_df['recall'].std():.4f}\"\n",
        "        })\n",
        "\n",
        "    # Add local results\n",
        "    if results['local']:\n",
        "        local_df = pd.DataFrame(results['local'])\n",
        "        comparison_data.append({\n",
        "            'Approach': 'Local',\n",
        "            'Strategy': 'N/A',\n",
        "            'Parameter': 'N/A',\n",
        "            'Accuracy': f\"{local_df['accuracy'].mean():.4f} ± {local_df['accuracy'].std():.4f}\",\n",
        "            'F1': f\"{local_df['f1'].mean():.4f} ± {local_df['f1'].std():.4f}\",\n",
        "            'Precision': f\"{local_df['precision'].mean():.4f} ± {local_df['precision'].std():.4f}\",\n",
        "            'Recall': f\"{local_df['recall'].mean():.4f} ± {local_df['recall'].std():.4f}\"\n",
        "        })\n",
        "\n",
        "    # Add federated results\n",
        "    for strategy_name, strategy_results in results['federated'].items():\n",
        "        for param_key, param_results in strategy_results.items():\n",
        "            if param_results:\n",
        "                param_df = pd.DataFrame(param_results)\n",
        "                comparison_data.append({\n",
        "                    'Approach': 'Federated',\n",
        "                    'Strategy': strategy_name,\n",
        "                    'Parameter': param_key,\n",
        "                    'Accuracy': f\"{param_df['accuracy'].mean():.4f} ± {param_df['accuracy'].std():.4f}\",\n",
        "                    'F1': f\"{param_df['f1'].mean():.4f} ± {param_df['f1'].std():.4f}\",\n",
        "                    'Precision': f\"{param_df['precision'].mean():.4f} ± {param_df['precision'].std():.4f}\",\n",
        "                    'Recall': f\"{param_df['recall'].mean():.4f} ± {param_df['recall'].std():.4f}\"\n",
        "                })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "print(\"Results analysis functions ready!\")"
      ],
      "metadata": {
        "id": "fsEmv-BIzCI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complete Experiment Execution\n",
        "\n",
        "This final section executes all three federated learning approaches and generates a comprehensive comparison, including:\n",
        "- Sequential execution of NN, SVM, and LR experiments\n",
        "- Cross-approach performance comparison\n",
        "- Visualization of results\n",
        "- Summary statistics and insights"
      ],
      "metadata": {
        "id": "uzsfqSFCzG2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION FUNCTIONS WITH BOXPLOTS AND MEANS\n",
        "# =============================================================================\n",
        "\n",
        "def create_performance_boxplots(all_model_results):\n",
        "    \"\"\"\n",
        "    Create comprehensive performance visualization with boxplots and means\n",
        "\n",
        "    Args:\n",
        "        all_model_results: Dictionary containing results for all models\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Creating performance boxplot visualizations...\")\n",
        "\n",
        "    # Set up the plotting style\n",
        "    plt.style.use('default')\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Federated Learning Performance Comparison (Boxplots with Means)', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Prepare data for plotting - collect all individual fold results\n",
        "    plot_data = []\n",
        "\n",
        "    for model_type, results in all_model_results.items():\n",
        "        # Centralized results - individual fold results\n",
        "        if results['centralized']:\n",
        "            for fold_result in results['centralized']:\n",
        "                plot_data.append({\n",
        "                    'Model': model_type.upper(),\n",
        "                    'Approach': 'Centralized',\n",
        "                    'Strategy': 'N/A',\n",
        "                    'Accuracy': fold_result['accuracy'],\n",
        "                    'F1': fold_result['f1'],\n",
        "                    'Precision': fold_result['precision'],\n",
        "                    'Recall': fold_result['recall']\n",
        "                })\n",
        "\n",
        "        # Local results - individual fold results\n",
        "        if results['local']:\n",
        "            for fold_result in results['local']:\n",
        "                plot_data.append({\n",
        "                    'Model': model_type.upper(),\n",
        "                    'Approach': 'Local',\n",
        "                    'Strategy': 'N/A',\n",
        "                    'Accuracy': fold_result['accuracy'],\n",
        "                    'F1': fold_result['f1'],\n",
        "                    'Precision': fold_result['precision'],\n",
        "                    'Recall': fold_result['recall']\n",
        "                })\n",
        "\n",
        "        # Federated results - get best performing configuration for each strategy\n",
        "        for strategy_name, strategy_results in results['federated'].items():\n",
        "            best_acc = 0\n",
        "            best_param_key = None\n",
        "\n",
        "            # Find best parameter configuration\n",
        "            for param_key, param_results in strategy_results.items():\n",
        "                if param_results:\n",
        "                    param_df = pd.DataFrame(param_results)\n",
        "                    acc = param_df['accuracy'].mean()\n",
        "                    if acc > best_acc:\n",
        "                        best_acc = acc\n",
        "                        best_param_key = param_key\n",
        "\n",
        "            # Add individual fold results for best configuration\n",
        "            if best_param_key and strategy_results[best_param_key]:\n",
        "                for fold_result in strategy_results[best_param_key]:\n",
        "                    plot_data.append({\n",
        "                        'Model': model_type.upper(),\n",
        "                        'Approach': 'Federated',\n",
        "                        'Strategy': strategy_name,\n",
        "                        'Accuracy': fold_result['accuracy'],\n",
        "                        'F1': fold_result['f1'],\n",
        "                        'Precision': fold_result['precision'],\n",
        "                        'Recall': fold_result['recall']\n",
        "                    })\n",
        "\n",
        "    plot_df = pd.DataFrame(plot_data)\n",
        "\n",
        "    # Create a combined approach-strategy column for better visualization\n",
        "    plot_df['Approach_Strategy'] = plot_df.apply(\n",
        "        lambda row: row['Approach'] if row['Approach'] != 'Federated'\n",
        "        else f\"FL-{row['Strategy']}\", axis=1\n",
        "    )\n",
        "\n",
        "    # Function to add means to boxplot\n",
        "    def add_means_to_boxplot(ax, data, x_col, y_col, hue_col):\n",
        "        \"\"\"Add mean points to boxplot with correct positioning\"\"\"\n",
        "\n",
        "        # Calculate means\n",
        "        means = data.groupby([x_col, hue_col])[y_col].mean().reset_index()\n",
        "\n",
        "        # Get unique categories\n",
        "        x_categories = data[x_col].unique()\n",
        "        hue_categories = data[hue_col].unique()\n",
        "\n",
        "        # Get the positions of the boxes\n",
        "        n_hue = len(hue_categories)\n",
        "\n",
        "        for i, x_cat in enumerate(x_categories):\n",
        "            for j, hue_cat in enumerate(hue_categories):\n",
        "                # Find the mean for this combination\n",
        "                mean_val = means[(means[x_col] == x_cat) & (means[hue_col] == hue_cat)][y_col]\n",
        "\n",
        "                if not mean_val.empty:\n",
        "                    # Calculate x position - this matches seaborn's positioning\n",
        "                    if n_hue > 1:\n",
        "                        # Multiple hue categories - spread them around the main position\n",
        "                        width = 0.8 / n_hue\n",
        "                        x_pos = i + (j - (n_hue - 1) / 2) * width\n",
        "                    else:\n",
        "                        # Single hue category - center on main position\n",
        "                        x_pos = i\n",
        "\n",
        "                    # Add mean point\n",
        "                    ax.scatter(x_pos, mean_val.iloc[0], color='red', s=60, marker='D',\n",
        "                             zorder=10, edgecolors='darkred', linewidth=1)\n",
        "\n",
        "    # Plot 1: Accuracy boxplot with means\n",
        "    sns.boxplot(data=plot_df, x='Model', y='Accuracy', hue='Approach_Strategy', ax=axes[0,0])\n",
        "    add_means_to_boxplot(axes[0,0], plot_df, 'Model', 'Accuracy', 'Approach_Strategy')\n",
        "    axes[0,0].set_title('Accuracy Distribution')\n",
        "    axes[0,0].set_ylim(0, 1)\n",
        "    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # Plot 2: F1 Score boxplot with means\n",
        "    sns.boxplot(data=plot_df, x='Model', y='F1', hue='Approach_Strategy', ax=axes[0,1])\n",
        "    add_means_to_boxplot(axes[0,1], plot_df, 'Model', 'F1', 'Approach_Strategy')\n",
        "    axes[0,1].set_title('F1 Score Distribution')\n",
        "    axes[0,1].set_ylim(0, 1)\n",
        "    axes[0,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # Plot 3: Precision boxplot with means\n",
        "    sns.boxplot(data=plot_df, x='Model', y='Precision', hue='Approach_Strategy', ax=axes[1,0])\n",
        "    add_means_to_boxplot(axes[1,0], plot_df, 'Model', 'Precision', 'Approach_Strategy')\n",
        "    axes[1,0].set_title('Precision Distribution')\n",
        "    axes[1,0].set_ylim(0, 1)\n",
        "    axes[1,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    # Plot 4: Recall boxplot with means\n",
        "    sns.boxplot(data=plot_df, x='Model', y='Recall', hue='Approach_Strategy', ax=axes[1,1])\n",
        "    add_means_to_boxplot(axes[1,1], plot_df, 'Model', 'Recall', 'Approach_Strategy')\n",
        "    axes[1,1].set_title('Recall Distribution')\n",
        "    axes[1,1].set_ylim(0, 1)\n",
        "    axes[1,1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nSummary Statistics (Mean ± Std):\")\n",
        "    summary_stats = plot_df.groupby(['Model', 'Approach_Strategy']).agg({\n",
        "        'Accuracy': ['mean', 'std'],\n",
        "        'F1': ['mean', 'std'],\n",
        "        'Precision': ['mean', 'std'],\n",
        "        'Recall': ['mean', 'std']\n",
        "    }).round(4)\n",
        "\n",
        "    print(summary_stats)\n",
        "\n",
        "    return plot_df\n",
        "\n",
        "def create_strategy_comparison_boxplot(all_model_results):\n",
        "    \"\"\"Create detailed boxplot comparison of federated learning strategies\"\"\"\n",
        "\n",
        "    print(\"Creating federated learning strategy comparison boxplots...\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "    fig.suptitle('Federated Learning Strategy Performance Distribution', fontsize=16, fontweight='bold')\n",
        "\n",
        "    model_types = ['nn', 'svm', 'lr']\n",
        "\n",
        "    for idx, model_type in enumerate(model_types):\n",
        "        if model_type in all_model_results:\n",
        "            results = all_model_results[model_type]\n",
        "\n",
        "            strategy_data = []\n",
        "\n",
        "            for strategy_name, strategy_results in results['federated'].items():\n",
        "                for param_key, param_results in strategy_results.items():\n",
        "                    if param_results:\n",
        "                        # Add all individual fold results\n",
        "                        for fold_result in param_results:\n",
        "                            strategy_data.append({\n",
        "                                'Strategy_Param': f\"{strategy_name}\\n({param_key})\",\n",
        "                                'Strategy': strategy_name,\n",
        "                                'Accuracy': fold_result['accuracy'],\n",
        "                                'F1': fold_result['f1']\n",
        "                            })\n",
        "\n",
        "            if strategy_data:\n",
        "                strategy_df = pd.DataFrame(strategy_data)\n",
        "\n",
        "                # Create boxplot\n",
        "                box_plot = sns.boxplot(data=strategy_df, x='Strategy_Param', y='Accuracy', ax=axes[idx])\n",
        "\n",
        "                # Add means with proper positioning\n",
        "                means = strategy_df.groupby('Strategy_Param')['Accuracy'].mean()\n",
        "\n",
        "                # Get the positions of the boxes from the boxplot\n",
        "                box_positions = [box.get_x() + box.get_width()/2 for box in box_plot.patches[::len(means)]]\n",
        "\n",
        "                # If we can't get positions from patches, use simple indexing\n",
        "                if len(box_positions) != len(means):\n",
        "                    box_positions = range(len(means))\n",
        "\n",
        "                # Add mean points\n",
        "                for pos, (param, mean_val) in zip(box_positions, means.items()):\n",
        "                    axes[idx].scatter(pos, mean_val, color='red', s=80, marker='D',\n",
        "                                    zorder=10, edgecolors='darkred', linewidth=1)\n",
        "\n",
        "                    # Add mean value labels\n",
        "                    axes[idx].text(pos, mean_val + 0.02, f'{mean_val:.3f}',\n",
        "                                 ha='center', va='bottom', fontsize=9,\n",
        "                                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
        "\n",
        "                axes[idx].set_title(f'{model_type.upper()} Model')\n",
        "                axes[idx].set_ylabel('Accuracy')\n",
        "                axes[idx].set_xlabel('Strategy Configuration')\n",
        "                axes[idx].tick_params(axis='x', rotation=45)\n",
        "                axes[idx].set_ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Visualization functions with boxplots and means ready!\")"
      ],
      "metadata": {
        "id": "Et2qKWxuzOB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# COMPREHENSIVE RESULTS SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "def generate_comprehensive_summary(all_model_results):\n",
        "    \"\"\"\n",
        "    Generate a comprehensive summary of all experimental results\n",
        "\n",
        "    Args:\n",
        "        all_model_results: Dictionary containing results for all models\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing comprehensive analysis\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"COMPREHENSIVE EXPERIMENTAL SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    summary = {\n",
        "        'overall_best': {},\n",
        "        'model_rankings': {},\n",
        "        'strategy_performance': {},\n",
        "        'insights': []\n",
        "    }\n",
        "\n",
        "    # Find overall best performance\n",
        "    best_accuracy = 0\n",
        "    best_f1 = 0\n",
        "    best_model_acc = None\n",
        "    best_model_f1 = None\n",
        "\n",
        "    print(\"\\n1. OVERALL BEST PERFORMANCE:\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for model_type, results in all_model_results.items():\n",
        "        print(f\"\\n{model_type.upper()} Model:\")\n",
        "\n",
        "        model_best_acc = 0\n",
        "        model_best_f1 = 0\n",
        "        model_best_config_acc = None\n",
        "        model_best_config_f1 = None\n",
        "\n",
        "        # Check all approaches for this model\n",
        "        approaches = ['centralized', 'local', 'federated']\n",
        "\n",
        "        for approach in approaches:\n",
        "            if approach in results and results[approach]:\n",
        "                if approach == 'federated':\n",
        "                    # Check all federated strategies\n",
        "                    for strategy_name, strategy_results in results[approach].items():\n",
        "                        for param_key, param_results in strategy_results.items():\n",
        "                            if param_results:\n",
        "                                param_df = pd.DataFrame(param_results)\n",
        "                                acc = param_df['accuracy'].mean()\n",
        "                                f1 = param_df['f1'].mean()\n",
        "\n",
        "                                config_name = f\"{approach}_{strategy_name}_{param_key}\"\n",
        "\n",
        "                                if acc > model_best_acc:\n",
        "                                    model_best_acc = acc\n",
        "                                    model_best_config_acc = config_name\n",
        "\n",
        "                                if f1 > model_best_f1:\n",
        "                                    model_best_f1 = f1\n",
        "                                    model_best_config_f1 = config_name\n",
        "                else:\n",
        "                    # Centralized or local\n",
        "                    approach_df = pd.DataFrame(results[approach])\n",
        "                    acc = approach_df['accuracy'].mean()\n",
        "                    f1 = approach_df['f1'].mean()\n",
        "\n",
        "                    if acc > model_best_acc:\n",
        "                        model_best_acc = acc\n",
        "                        model_best_config_acc = approach\n",
        "\n",
        "                    if f1 > model_best_f1:\n",
        "                        model_best_f1 = f1\n",
        "                        model_best_config_f1 = approach\n",
        "\n",
        "        print(f\"  Best Accuracy: {model_best_acc:.4f} ({model_best_config_acc})\")\n",
        "        print(f\"  Best F1: {model_best_f1:.4f} ({model_best_config_f1})\")\n",
        "\n",
        "        # Update overall best\n",
        "        if model_best_acc > best_accuracy:\n",
        "            best_accuracy = model_best_acc\n",
        "            best_model_acc = f\"{model_type}_{model_best_config_acc}\"\n",
        "\n",
        "        if model_best_f1 > best_f1:\n",
        "            best_f1 = model_best_f1\n",
        "            best_model_f1 = f\"{model_type}_{model_best_config_f1}\"\n",
        "\n",
        "    summary['overall_best']['accuracy'] = {'value': best_accuracy, 'config': best_model_acc}\n",
        "    summary['overall_best']['f1'] = {'value': best_f1, 'config': best_model_f1}\n",
        "\n",
        "    print(f\"\\nOVERALL BEST ACCURACY: {best_accuracy:.4f} ({best_model_acc})\")\n",
        "    print(f\"OVERALL BEST F1: {best_f1:.4f} ({best_model_f1})\")\n",
        "\n",
        "    # Strategy performance analysis\n",
        "    print(f\"\\n2. FEDERATED LEARNING STRATEGY ANALYSIS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    strategy_performance = {}\n",
        "\n",
        "    for strategy_name in strategies.keys():\n",
        "        strategy_results = []\n",
        "\n",
        "        for model_type, results in all_model_results.items():\n",
        "            if strategy_name in results['federated']:\n",
        "                for param_key, param_results in results['federated'][strategy_name].items():\n",
        "                    if param_results:\n",
        "                        param_df = pd.DataFrame(param_results)\n",
        "                        strategy_results.append({\n",
        "                            'model': model_type,\n",
        "                            'param': param_key,\n",
        "                            'accuracy': param_df['accuracy'].mean(),\n",
        "                            'f1': param_df['f1'].mean()\n",
        "                        })\n",
        "\n",
        "        if strategy_results:\n",
        "            strategy_df = pd.DataFrame(strategy_results)\n",
        "            avg_acc = strategy_df['accuracy'].mean()\n",
        "            avg_f1 = strategy_df['f1'].mean()\n",
        "\n",
        "            strategy_performance[strategy_name] = {\n",
        "                'avg_accuracy': avg_acc,\n",
        "                'avg_f1': avg_f1,\n",
        "                'best_accuracy': strategy_df['accuracy'].max(),\n",
        "                'best_f1': strategy_df['f1'].max()\n",
        "            }\n",
        "\n",
        "            print(f\"{strategy_name}:\")\n",
        "            print(f\"  Average Accuracy: {avg_acc:.4f}\")\n",
        "            print(f\"  Average F1: {avg_f1:.4f}\")\n",
        "            print(f\"  Best Accuracy: {strategy_df['accuracy'].max():.4f}\")\n",
        "            print(f\"  Best F1: {strategy_df['f1'].max():.4f}\")\n",
        "\n",
        "    summary['strategy_performance'] = strategy_performance\n",
        "\n",
        "    # Generate insights\n",
        "    insights = []\n",
        "\n",
        "    # Best performing model\n",
        "    model_performances = {}\n",
        "    for model_type, results in all_model_results.items():\n",
        "        best_acc = 0\n",
        "        for approach in ['centralized', 'local', 'federated']:\n",
        "            if approach in results and results[approach]:\n",
        "                if approach == 'federated':\n",
        "                    for strategy_name, strategy_results in results[approach].items():\n",
        "                        for param_key, param_results in strategy_results.items():\n",
        "                            if param_results:\n",
        "                                param_df = pd.DataFrame(param_results)\n",
        "                                acc = param_df['accuracy'].mean()\n",
        "                                best_acc = max(best_acc, acc)\n",
        "                else:\n",
        "                    approach_df = pd.DataFrame(results[approach])\n",
        "                    acc = approach_df['accuracy'].mean()\n",
        "                    best_acc = max(best_acc, acc)\n",
        "\n",
        "        model_performances[model_type] = best_acc\n",
        "\n",
        "    best_model = max(model_performances, key=model_performances.get)\n",
        "    insights.append(f\"Best performing model: {best_model.upper()} (Accuracy: {model_performances[best_model]:.4f})\")\n",
        "\n",
        "    # Best strategy\n",
        "    if strategy_performance:\n",
        "        best_strategy = max(strategy_performance, key=lambda x: strategy_performance[x]['avg_accuracy'])\n",
        "        insights.append(f\"Best FL strategy: {best_strategy} (Avg Accuracy: {strategy_performance[best_strategy]['avg_accuracy']:.4f})\")\n",
        "\n",
        "    summary['insights'] = insights\n",
        "\n",
        "    print(f\"\\n3. KEY INSIGHTS:\")\n",
        "    print(\"-\" * 20)\n",
        "    for insight in insights:\n",
        "        print(f\"• {insight}\")\n",
        "\n",
        "    return summary\n",
        "\n",
        "print(\"Comprehensive summary function ready!\")"
      ],
      "metadata": {
        "id": "hSVCqg8PzSNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN EXECUTION BLOCK\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function that runs all experiments\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(\"FEDERATED LEARNING COMPREHENSIVE COMPARISON STUDY\")\n",
        "    print(\"Neural Network vs SVM vs Logistic Regression\")\n",
        "    print(\"WITH BOXPLOTS, MEANS, AND 20-FOLD CROSS-VALIDATION\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    # Check if data is loaded\n",
        "    if 'X' not in globals() or 'y' not in globals():\n",
        "        print(\"ERROR: Data not loaded. Please run the data loading section first.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Dataset shape: {X.shape}\")\n",
        "    print(f\"Class distribution: {np.bincount(y)}\")\n",
        "    print(f\"Cross-validation folds: {NUM_FOLDS}\")\n",
        "    print(f\"Centralized/Local max iterations: 200\")\n",
        "    print(f\"Federated learning max iterations: 20\")\n",
        "\n",
        "    # Store all results\n",
        "    all_model_results = {}\n",
        "\n",
        "    # Define models to test with their DEFAULT hyperparameters\n",
        "    models_to_test = [\n",
        "        ('nn', 'Neural Network', None),\n",
        "        ('svm', 'Support Vector Machine', None),\n",
        "        ('lr', 'Logistic Regression', None)\n",
        "    ]\n",
        "\n",
        "    # Run experiments for each model\n",
        "    for model_type, model_name, custom_hyperparams in models_to_test:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"STARTING {model_name.upper()} EXPERIMENTS\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        try:\n",
        "            # Run complete experiment with custom hyperparameters\n",
        "            results = run_complete_experiment(\n",
        "                X, y, model_type, apply_splines=True,\n",
        "                custom_hyperparams=custom_hyperparams\n",
        "            )\n",
        "            all_model_results[model_type] = results\n",
        "\n",
        "            # Analyze results for this model\n",
        "            analysis = analyze_results(results, model_type)\n",
        "\n",
        "            # Create comparison table\n",
        "            comparison_table = create_comparison_table(results, model_type)\n",
        "\n",
        "            print(f\"\\n{model_name.upper()} experiments completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR in {model_name} experiments: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Generate comprehensive comparison if results available\n",
        "    if all_model_results:\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(\"GENERATING COMPREHENSIVE COMPARISON WITH BOXPLOTS\")\n",
        "        print(f\"{'='*100}\")\n",
        "\n",
        "        # Create boxplot visualizations\n",
        "        try:\n",
        "            print(\"Creating performance boxplots...\")\n",
        "            plot_df = create_performance_boxplots(all_model_results)\n",
        "            print(\"Creating strategy comparison boxplots...\")\n",
        "            create_strategy_comparison_boxplot(all_model_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating boxplots: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "        # Generate comprehensive summary\n",
        "        try:\n",
        "            print(\"Generating comprehensive summary...\")\n",
        "            comprehensive_summary = generate_comprehensive_summary(all_model_results)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating summary: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "        # Save results\n",
        "        try:\n",
        "            print(\"Saving results to CSV files...\")\n",
        "            save_results(all_model_results, filename_prefix=\"fl_results_20folds\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results: {e}\")\n",
        "\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
        "        print(f\"{'='*100}\")\n",
        "\n",
        "        # Display key findings\n",
        "        if 'comprehensive_summary' in locals() and comprehensive_summary and 'insights' in comprehensive_summary:\n",
        "            print(\"\\nKEY FINDINGS:\")\n",
        "            for insight in comprehensive_summary['insights']:\n",
        "                print(f\"• {insight}\")\n",
        "\n",
        "        print(\"\\nResults Summary:\")\n",
        "        print(f\"Completed {NUM_FOLDS} cross-validation folds for each approach\")\n",
        "        print(f\"Tested {len(all_model_results)} different models\")\n",
        "        print(f\"Evaluated multiple federated learning strategies with model-specific hyperparameters\")\n",
        "        print(f\"Used 200 iterations for centralized and local training\")\n",
        "        print(f\"Used 20 iterations for federated learning\")\n",
        "        print(f\"Generated boxplot visualizations with means\")\n",
        "        print(f\"Saved detailed results to CSV files\")\n",
        "\n",
        "        return all_model_results, comprehensive_summary if 'comprehensive_summary' in locals() else None\n",
        "\n",
        "    else:\n",
        "        print(\"No results to analyze. Please check the error messages above.\")\n",
        "        return None, None\n",
        "\n",
        "# Save results function\n",
        "def save_results(all_model_results, filename_prefix=\"fl_results\"):\n",
        "    \"\"\"Save results to CSV files\"\"\"\n",
        "\n",
        "    print(\"Saving results to CSV files...\")\n",
        "\n",
        "    # Create a metadata file\n",
        "    metadata = {\n",
        "        'experiment_info': {\n",
        "            'num_folds': NUM_FOLDS,\n",
        "            'num_partitions': NUM_PARTITIONS,\n",
        "            'fl_rounds': NUM_ROUNDS,\n",
        "            'centralized_local_iterations': 200,\n",
        "            'federated_iterations': 20,\n",
        "            'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Save metadata\n",
        "    with open(f\"{filename_prefix}_metadata.txt\", 'w') as f:\n",
        "        for key, value in metadata['experiment_info'].items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "    # Save detailed results for each model\n",
        "    for model_type, results in all_model_results.items():\n",
        "        # Save centralized results\n",
        "        if results['centralized']:\n",
        "            centralized_df = pd.DataFrame(results['centralized'])\n",
        "            centralized_df['fold'] = range(1, len(centralized_df) + 1)\n",
        "            centralized_df.to_csv(f\"{filename_prefix}_{model_type}_centralized.csv\", index=False)\n",
        "            print(f\"  Saved: {filename_prefix}_{model_type}_centralized.csv ({len(centralized_df)} folds)\")\n",
        "\n",
        "        # Save local results\n",
        "        if results['local']:\n",
        "            local_df = pd.DataFrame(results['local'])\n",
        "            local_df['fold'] = range(1, len(local_df) + 1)\n",
        "            local_df.to_csv(f\"{filename_prefix}_{model_type}_local.csv\", index=False)\n",
        "            print(f\"  Saved: {filename_prefix}_{model_type}_local.csv ({len(local_df)} folds)\")\n",
        "\n",
        "        # Save federated results\n",
        "        for strategy_name, strategy_results in results['federated'].items():\n",
        "            for param_key, param_results in strategy_results.items():\n",
        "                if param_results:\n",
        "                    param_df = pd.DataFrame(param_results)\n",
        "                    param_df['fold'] = range(1, len(param_df) + 1)\n",
        "                    filename = f\"{filename_prefix}_{model_type}_{strategy_name}_{param_key}.csv\"\n",
        "                    param_df.to_csv(filename, index=False)\n",
        "                    print(f\"  Saved: {filename} ({len(param_df)} folds)\")\n",
        "\n",
        "    # Create summary statistics file\n",
        "    summary_data = []\n",
        "    for model_type, results in all_model_results.items():\n",
        "        # Centralized summary\n",
        "        if results['centralized']:\n",
        "            centralized_df = pd.DataFrame(results['centralized'])\n",
        "            summary_data.append({\n",
        "                'Model': model_type.upper(),\n",
        "                'Approach': 'Centralized',\n",
        "                'Strategy': 'N/A',\n",
        "                'Parameter': 'N/A',\n",
        "                'Accuracy_Mean': centralized_df['accuracy'].mean(),\n",
        "                'Accuracy_Std': centralized_df['accuracy'].std(),\n",
        "                'F1_Mean': centralized_df['f1'].mean(),\n",
        "                'F1_Std': centralized_df['f1'].std(),\n",
        "                'Precision_Mean': centralized_df['precision'].mean(),\n",
        "                'Precision_Std': centralized_df['precision'].std(),\n",
        "                'Recall_Mean': centralized_df['recall'].mean(),\n",
        "                'Recall_Std': centralized_df['recall'].std(),\n",
        "                'Num_Folds': len(centralized_df)\n",
        "            })\n",
        "\n",
        "        # Local summary\n",
        "        if results['local']:\n",
        "            local_df = pd.DataFrame(results['local'])\n",
        "            summary_data.append({\n",
        "                'Model': model_type.upper(),\n",
        "                'Approach': 'Local',\n",
        "                'Strategy': 'N/A',\n",
        "                'Parameter': 'N/A',\n",
        "                'Accuracy_Mean': local_df['accuracy'].mean(),\n",
        "                'Accuracy_Std': local_df['accuracy'].std(),\n",
        "                'F1_Mean': local_df['f1'].mean(),\n",
        "                'F1_Std': local_df['f1'].std(),\n",
        "                'Precision_Mean': local_df['precision'].mean(),\n",
        "                'Precision_Std': local_df['precision'].std(),\n",
        "                'Recall_Mean': local_df['recall'].mean(),\n",
        "                'Recall_Std': local_df['recall'].std(),\n",
        "                'Num_Folds': len(local_df)\n",
        "            })\n",
        "\n",
        "        # Federated summary\n",
        "        for strategy_name, strategy_results in results['federated'].items():\n",
        "            for param_key, param_results in strategy_results.items():\n",
        "                if param_results:\n",
        "                    param_df = pd.DataFrame(param_results)\n",
        "                    summary_data.append({\n",
        "                        'Model': model_type.upper(),\n",
        "                        'Approach': 'Federated',\n",
        "                        'Strategy': strategy_name,\n",
        "                        'Parameter': param_key,\n",
        "                        'Accuracy_Mean': param_df['accuracy'].mean(),\n",
        "                        'Accuracy_Std': param_df['accuracy'].std(),\n",
        "                        'F1_Mean': param_df['f1'].mean(),\n",
        "                        'F1_Std': param_df['f1'].std(),\n",
        "                        'Precision_Mean': param_df['precision'].mean(),\n",
        "                        'Precision_Std': param_df['precision'].std(),\n",
        "                        'Recall_Mean': param_df['recall'].mean(),\n",
        "                        'Recall_Std': param_df['recall'].std(),\n",
        "                        'Num_Folds': len(param_df)\n",
        "                    })\n",
        "\n",
        "    # Save summary statistics\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df.to_csv(f\"{filename_prefix}_summary_statistics.csv\", index=False)\n",
        "    print(f\"  Saved: {filename_prefix}_summary_statistics.csv\")\n",
        "\n",
        "    print(\"Results saved successfully!\")\n",
        "    return summary_df\n",
        "\n",
        "print(\"Main execution functions ready!\")"
      ],
      "metadata": {
        "id": "eGXEN_OxzVtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Complete Experiment\n",
        "\n",
        "Execute the following cell to run all experiments. This will:\n",
        "\n",
        "1. **Sequential Execution**: Run NN, SVM, and LR experiments with cross-validation\n",
        "2. **Comprehensive Analysis**: Compare all approaches and strategies\n",
        "3. **Visualization**: Generate performance plots and comparisons\n",
        "4. **Summary Report**: Provide insights and recommendations\n",
        "\n",
        "**Note**: This may take several hours to complete depending on your system."
      ],
      "metadata": {
        "id": "pTUjP3P8zaF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXECUTE THE COMPLETE EXPERIMENT\n",
        "# =============================================================================\n",
        "\n",
        "# Run all experiments\n",
        "if __name__ == \"__main__\":\n",
        "    # Execute main experiment\n",
        "    all_results, summary = main()\n",
        "\n",
        "    # Enhanced result saving if successful\n",
        "    if all_results is not None:\n",
        "        try:\n",
        "            summary_stats_df = save_results(all_results)\n",
        "\n",
        "            print(f\"\\n{'='*100}\")\n",
        "            print(\"FINAL EXPERIMENTAL SUMMARY\")\n",
        "            print(f\"{'='*100}\")\n",
        "            print(f\"Completed comprehensive federated learning comparison\")\n",
        "            print(f\"Generated boxplot visualizations with means and distributions\")\n",
        "            print(f\"Performed {NUM_FOLDS} cross-validation folds per approach\")\n",
        "            print(f\"Saved detailed results and summary statistics to CSV files\")\n",
        "            print(f\"Model-specific hyperparameter optimization completed\")\n",
        "            print(f\"{'='*100}\")\n",
        "\n",
        "            # Display top performing configurations\n",
        "            if 'summary_stats_df' in locals() and not summary_stats_df.empty:\n",
        "                print(\"\\nTOP PERFORMING CONFIGURATIONS:\")\n",
        "                top_configs = summary_stats_df.nlargest(5, 'Accuracy_Mean')[\n",
        "                    ['Model', 'Approach', 'Strategy', 'Parameter', 'Accuracy_Mean', 'Accuracy_Std']\n",
        "                ]\n",
        "                print(top_configs.to_string(index=False))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in enhanced result saving: {e}\")\n",
        "            # Fallback to basic saving\n",
        "            save_results(all_results, filename_prefix=\"fl_results_20folds_basic\")\n",
        "\n",
        "        print(\"\\nExperiment completed successfully!\")\n",
        "        print(\"Check the generated CSV files for detailed results\")\n",
        "        print(\"Review the boxplot visualizations for performance distributions\")\n",
        "\n",
        "    else:\n",
        "        print(\"Experiment failed. Please check the error messages above.\")\n",
        "        print(\"Common issues: data not loaded, CUDA problems, or configuration errors\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2tA5XHPjzcwc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
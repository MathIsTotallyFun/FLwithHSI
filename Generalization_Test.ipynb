{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iR6Ku7zzlHo"
      },
      "source": [
        "# Federated Learning Generalizability Study: Multi-Model Comparison\n",
        "\n",
        "## Overview\n",
        "This notebook implements and compares three federated learning approaches for tomato disease classification using spectral data. The study evaluates model generalization across different federated learning strategies.\n",
        "\n",
        "## Models Implemented\n",
        "1. **Logistic Regression** - Using SGDClassifier with log loss\n",
        "2. **SVM (Support Vector Machine)** - Using SGDClassifier with hinge loss\n",
        "3. **Neural Network** - Using PyTorch with cross-entropy loss\n",
        "\n",
        "## Evaluation Framework\n",
        "- **Client Configuration**: 5 clients total (4 for training, 1 held out for testing)\n",
        "- **Cross-Validation**: 20-fold cross-validation for robust statistical evaluation\n",
        "- **Feature Engineering**: B-spline basis transformation from raw spectral data\n",
        "- **Evaluation Strategies**:\n",
        "  - Federated Learning (FedAvg)\n",
        "  - Personalized Federated Learning\n",
        "  - Local Training\n",
        "  - Local Average\n",
        "  - Centralized Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVg6WBlVzngo"
      },
      "outputs": [],
      "source": [
        "# Import all required libraries for all three approaches\n",
        "!pip install -q flwr[simulation]\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Federated learning imports\n",
        "import flwr as fl\n",
        "from flwr.common import Context, Parameters, ndarrays_to_parameters\n",
        "from flwr.client import NumPyClient, Client, ClientApp\n",
        "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr.server.strategy import FedAvg, FedProx, FedAdam, FedOpt\n",
        "\n",
        "# ML imports\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import hinge_loss, accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.interpolate import BSpline, make_lsq_spline\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Configuration\n",
        "NUM_PARTITIONS = 4  # 4 training clients + 1 test client = 5 total\n",
        "basisnum = 10\n",
        "NUM_FOLDS = 2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Environment setup complete!\")\n",
        "print(f\"PyTorch device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing Pipeline\n",
        "\n",
        "### Data Loading and Preprocessing\n",
        "```python\n",
        "# Load multiple CSV files and combine them\n",
        "dataframes = []\n",
        "labels = []\n",
        "all_data = []\n",
        "\n",
        "for file in uploaded:\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    df = df.T  # Transpose data\n",
        "    df.columns = df.iloc[0]  # Use first row as column headers\n",
        "    df = df.drop(df.index[0])  # Remove header row\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')  # Convert to numeric\n",
        "    label = 1 if \"diseased\" in file.lower() else 0  # Binary classification\n",
        "    df[\"label\"] = label\n",
        "    all_data.append(df)\n",
        "```\n",
        "###Data Structure:\n",
        "- Input: CSV files containing spectral data\n",
        "- Labels: Binary classification (0=healthy, 1=diseased)\n",
        "- Features: Spectral measurements (300 wavelengths)\n",
        "\n",
        "###Feature Extraction\n",
        "```python\n",
        "df_all = pd.concat(all_data, ignore_index=True)\n",
        "feature_cols = df_all.columns[2:-1]  # Select relevant feature columns\n",
        "X = df_all[feature_cols].values  # Feature matrix (N, 300)\n",
        "y = df_all['label'].values  # Target labels (N,)\n",
        "```"
      ],
      "metadata": {
        "id": "KmCzx5cdUt3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading section - replace with your actual data loading\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "dataframes = []\n",
        "labels = []\n",
        "all_data = []\n",
        "\n",
        "for file in uploaded:\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    df = df.T\n",
        "    df.columns = df.iloc[0]\n",
        "    df = df.drop(df.index[0])\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "    print(f\"{file}: shape = {df.shape}\")\n",
        "    label = 1 if \"diseased\" in file.lower() else 0\n",
        "    df[\"label\"] = label\n",
        "    all_data.append(df)\n",
        "\n",
        "df_all = pd.concat(all_data, ignore_index=True)\n",
        "feature_cols = df_all.columns[2:-1]  # remove unneeded columns\n",
        "\n",
        "X = df_all[feature_cols].values  # 2D array (N, 300)\n",
        "y = df_all['label'].values  # labels (N,)\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "metadata": {
        "id": "YMcMfNvAEYxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Engineering\n",
        "\n",
        "###B-spline Basis Transformation\n",
        "Purpose: Reduces dimensionality from 300 spectral bands to configurable number of B-spline basis functions while preserving spectral characteristics and meets federated learning requirements."
      ],
      "metadata": {
        "id": "e5CTjYq_U06z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_knot_vector(num_basis, spline_order):\n",
        "    num_total_knots = num_basis + spline_order + 1\n",
        "    num_internal_knots = num_total_knots - 2 * (spline_order + 1)\n",
        "    internal_knots = np.linspace(0, 1, num_internal_knots + 2)[1:-1]\n",
        "    t = np.concatenate((\n",
        "        np.repeat(0.0, spline_order + 1),\n",
        "        internal_knots,\n",
        "        np.repeat(1.0, spline_order + 1)\n",
        "    ))\n",
        "    return t\n",
        "\n",
        "def fit_bspline_basis(X, num_basis=10, spline_order=3):\n",
        "    N, D = X.shape\n",
        "    x_domain = np.linspace(0, 1, D)\n",
        "    t = compute_knot_vector(num_basis, spline_order)\n",
        "\n",
        "    coeffs = np.zeros((N, num_basis))\n",
        "    for i in range(N):\n",
        "        y = X[i]\n",
        "        spline = make_lsq_spline(x_domain, y, t, spline_order)\n",
        "        coeffs[i] = spline.c\n",
        "\n",
        "    return coeffs\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "G79OxS7jKQ25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Client Data Preparation Functions\n",
        "\n",
        "These act as a pipeline, calling the b-spline function and then standardizing the dataset as well. This can easily be called later."
      ],
      "metadata": {
        "id": "NQijLyG7VE4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(X_data, num_basis=basisnum, scaler=None):\n",
        "    \"\"\"Apply B-spline transformation and scaling in one step\"\"\"\n",
        "    X_reduced = fit_bspline_basis(X_data, num_basis=num_basis, spline_order=3)\n",
        "    if scaler is None:\n",
        "        scaler = StandardScaler()\n",
        "        return scaler.fit_transform(X_reduced), scaler\n",
        "    return scaler.transform(X_reduced), scaler\n",
        "\n",
        "# Refactored client data preparation\n",
        "def prepare_client_data(X_train_partitions_raw, X_test_partitions_raw,\n",
        "                       y_train_partitions, y_test_partitions):\n",
        "    \"\"\"Prepare all client data with preprocessing\"\"\"\n",
        "    client_train_data, client_val_data = {}, {}\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        X_train_scaled, scaler = preprocess_data(X_train_partitions_raw[cid])\n",
        "        X_test_scaled, _ = preprocess_data(X_test_partitions_raw[cid], scaler=scaler)\n",
        "\n",
        "        client_train_data[cid] = (X_train_scaled, y_train_partitions[cid])\n",
        "        client_val_data[cid] = (X_test_scaled, y_test_partitions[cid])\n",
        "\n",
        "    return client_train_data, client_val_data"
      ],
      "metadata": {
        "id": "ioA4tFSbMv_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression Setup\n",
        "\n",
        "This code sets up a basic federated learning workflow using the Flower library and scikit-learn's SGDClassifier (log loss).\n",
        "\n",
        "Parameter management: Functions get, set, and average the model's weights across different clients.  \n",
        "Model utilities: Functions for incremental training (partial_fit) and evaluating with standard metrics (loss, accuracy, precision, recall, F1).  \n",
        "FlowerClient: Each client handles its own data partition, receives and updates model parameters, trains locally, and reports metrics.  \n",
        "Server functions: Aggregate client metrics, perform federated averaging, and orchestrate rounds.  \n",
        "Configuration: Specifies number of rounds and system resources for clients."
      ],
      "metadata": {
        "id": "yUAVTgZtVgoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(model):\n",
        "    return [model.coef_.copy(), model.intercept_.copy()]\n",
        "\n",
        "def set_parameters(model, parameters):\n",
        "    model.coef_ = parameters[0].copy()\n",
        "    model.intercept_ = parameters[1].copy()\n",
        "\n",
        "def average_parameters(parameter_list):\n",
        "    avg_coef = np.mean([params[0] for params in parameter_list], axis=0)\n",
        "    avg_intercept = np.mean([params[1] for params in parameter_list], axis=0)\n",
        "    return [avg_coef, avg_intercept]\n",
        "\n",
        "def train_model(model, X, y):\n",
        "    if not hasattr(model, \"coef_\"):\n",
        "        model.partial_fit(X, y, classes=np.array([0,1]))\n",
        "    else:\n",
        "        model.partial_fit(X, y)\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    preds = model.predict(X)\n",
        "    y_prob = model.predict_proba(X)\n",
        "    return {\n",
        "        \"loss\": log_loss(y, y_prob, labels=model.classes_),\n",
        "        \"accuracy\": accuracy_score(y, preds),\n",
        "        \"precision\": precision_score(y, preds, average=\"binary\", zero_division=0),\n",
        "        \"recall\": recall_score(y, preds, average=\"binary\", zero_division=0),\n",
        "        \"f1\": f1_score(y, preds, average=\"binary\", zero_division=0),\n",
        "    }\n",
        "\n",
        "def initialize_model(n_features):\n",
        "    model = SGDClassifier(\n",
        "        loss=\"log_loss\",\n",
        "        max_iter=20,\n",
        "        tol=None,\n",
        "        warm_start=True,\n",
        "        learning_rate=\"optimal\",\n",
        "        eta0=0.01,\n",
        "        random_state=42,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id: int, personalized=False):\n",
        "        self.partition_id = partition_id\n",
        "        self.model = initialize_model(X_train_full.shape[1])\n",
        "        self.X_train, self.y_train = client_train_data[partition_id]\n",
        "        self.X_val, self.y_val = client_val_data[partition_id]\n",
        "        self.personalized = personalized\n",
        "        self.model.partial_fit(self.X_train, self.y_train, classes=np.array([0, 1]))\n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        train_model(self.model, self.X_train, self.y_train)\n",
        "        return get_parameters(self.model), len(self.X_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        metrics = evaluate_model(self.model, self.X_val, self.y_val)\n",
        "        # metrics = evaluate_model(self.model, self.X_train, self.y_train)\n",
        "        loss = metrics.pop(\"loss\", 0.0)\n",
        "        return loss, len(self.y_val), metrics\n",
        "\n",
        "final_fl_metrics = None\n",
        "final_parameters = None\n",
        "\n",
        "def get_evaluate_fn():\n",
        "    def evaluate(server_round, parameters, config):\n",
        "        all_metrics = []\n",
        "        for cid in range(NUM_PARTITIONS):\n",
        "            model = initialize_model(X_train_full.shape[1])\n",
        "            X_val, y_val = client_val_data[cid]\n",
        "            X_train, y_train = client_train_data[cid]\n",
        "            set_parameters(model, parameters)\n",
        "            model.classes_ = np.unique(y_train_full)\n",
        "            metrics = evaluate_model(model, X_val, y_val)\n",
        "            # metrics = evaluate_model(model, X_train, y_train)\n",
        "            all_metrics.append(metrics)\n",
        "\n",
        "        df_metrics = pd.DataFrame(all_metrics)\n",
        "        avg_metrics = df_metrics.mean().to_dict()\n",
        "\n",
        "        if server_round == 10:\n",
        "            global final_fl_metrics, final_parameters\n",
        "            final_fl_metrics = avg_metrics.copy()\n",
        "            final_parameters = parameters\n",
        "\n",
        "        return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "    return evaluate\n",
        "\n",
        "def server_fn(context):\n",
        "    strategy = FedAvg(\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        evaluate_fn=get_evaluate_fn(),\n",
        "        fit_metrics_aggregation_fn=None,\n",
        "        evaluate_metrics_aggregation_fn=None\n",
        "    )\n",
        "    return ServerAppComponents(config=ServerConfig(num_rounds=10), strategy=strategy)\n",
        "\n",
        "def client_fn(context):\n",
        "    cid = context.node_config.get(\"partition-id\", 0)\n",
        "    return FlowerClient(cid).to_client()\n",
        "\n",
        "client = ClientApp(client_fn=client_fn)\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0}}\n"
      ],
      "metadata": {
        "id": "42SrvqBSEe-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross-Validation Evaluation of Federated and Baseline Models for LR\n",
        "This script runs repeated train/test splits to compare federated, personalized, local, and centralized models.\n",
        "\n",
        "- For each fold, the data is split into training, testing, and personalized subsets with stratification.\n",
        "- Each partition is preprocessed and used to prepare client data.\n",
        "- A federated simulation runs, aggregating client models.\n",
        "- Evaluations are performed for:\n",
        "federated learning (global model),\n",
        "personalized federated (fine-tuned global model),\n",
        "local-only models (trained on each client),\n",
        "averaged local models (ensemble of locals),\n",
        "and a centralized model (trained on pooled data).\n",
        "- All results and summary statistics are saved for further analysis."
      ],
      "metadata": {
        "id": "W01ISvzVWZn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "\n",
        "all_results_by_basis = {}\n",
        "fold = 0\n",
        "\n",
        "print(f\"--- Basis {basisnum} ---\")\n",
        "for repeat in range(NUM_FOLDS):\n",
        "    print(f\"--- Fold {repeat + 1}/{NUM_FOLDS} ---\")\n",
        "    # Combined data splitting\n",
        "    X_rest, X_new, y_rest, y_new = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, shuffle=True, random_state=repeat)\n",
        "\n",
        "    X_train_personal_raw, X_test_personal_raw, y_train_personal, y_test_personal = train_test_split(\n",
        "        X_new, y_new, test_size=0.2, stratify=y_new, random_state=42)\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X_rest, y_rest, test_size=0.2, stratify=y_rest, shuffle=True, random_state=repeat)\n",
        "\n",
        "    # Preprocessing for central and new data\n",
        "    X_train_scaled_central, scaler_central = preprocess_data(X_train_raw)\n",
        "    X_test_scaled_central, _ = preprocess_data(X_test_raw, scaler=scaler_central)\n",
        "    X_new_scaled, _ = preprocess_data(X_new)\n",
        "\n",
        "    #Apply same preprocessing to personalized data\n",
        "    X_train_personal_scaled, personal_scaler = preprocess_data(X_train_personal_raw)\n",
        "    X_test_personal_scaled, _ = preprocess_data(X_test_personal_raw, scaler=personal_scaler)\n",
        "\n",
        "    X_train_partitions_raw = np.array_split(X_train_raw, NUM_PARTITIONS)\n",
        "    y_train_partitions = np.array_split(y_train, NUM_PARTITIONS)\n",
        "    X_test_partitions_raw = np.array_split(X_test_raw, NUM_PARTITIONS)\n",
        "    y_test_partitions = np.array_split(y_test, NUM_PARTITIONS)\n",
        "    client_train_data = {}\n",
        "    client_val_data = {}\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        X_train_reduced = fit_bspline_basis(X_train_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
        "\n",
        "        X_test_reduced = fit_bspline_basis(X_test_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        X_test_scaled = scaler.transform(X_test_reduced)\n",
        "\n",
        "        client_train_data[cid] = (X_train_scaled, y_train_partitions[cid])\n",
        "        client_val_data[cid] = (X_test_scaled, y_test_partitions[cid])\n",
        "\n",
        "    run_simulation(\n",
        "        server_app=server,\n",
        "        client_app=client,\n",
        "        num_supernodes=NUM_PARTITIONS,\n",
        "        backend_config=backend_config\n",
        "    )\n",
        "\n",
        "    model = initialize_model(X_new_scaled.shape[1])\n",
        "    set_parameters(model, final_parameters)\n",
        "    model.classes_ = np.unique(y_new)\n",
        "    final_fl_metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "\n",
        "    def run_personalized_evaluation(final_parameters):\n",
        "        model = initialize_model(X_train_personal_scaled.shape[1])\n",
        "        set_parameters(model, final_parameters)\n",
        "        # Train on train split\n",
        "        model.partial_fit(X_train_personal_scaled, y_train_personal, classes=np.unique(y))\n",
        "        # Evaluate on test split\n",
        "        metrics = evaluate_model(model, X_test_personal_scaled, y_test_personal)\n",
        "        return metrics\n",
        "\n",
        "    personalized_metrics = run_personalized_evaluation(final_parameters)\n",
        "\n",
        "    local_metrics_list = []\n",
        "    local_models = []\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        model = SGDClassifier(\n",
        "            loss=\"log_loss\", max_iter=200, tol=None,\n",
        "            warm_start=True, learning_rate=\"optimal\", eta0=0.01\n",
        "        )\n",
        "        X_train_client, y_train_client = client_train_data[cid]\n",
        "        # Train local model on client data\n",
        "        train_model(model, X_train_client, y_train_client)\n",
        "        local_models.append(model)\n",
        "        # Evaluate local model on the common new data\n",
        "        metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "        local_metrics_list.append(metrics)\n",
        "\n",
        "    # Average metrics from local models evaluated on X_new_scaled\n",
        "    local_metrics = pd.DataFrame(local_metrics_list).mean().to_dict()\n",
        "\n",
        "    # Now average the local models' weights\n",
        "    def average_sgd_models(models):\n",
        "        # This assumes sklearn SGDClassifier, average coef_ and intercept_\n",
        "        avg_model = initialize_model(X_new_scaled.shape[1])\n",
        "\n",
        "        coefs = np.array([m.coef_ for m in models])\n",
        "        intercepts = np.array([m.intercept_ for m in models])\n",
        "\n",
        "        avg_coef = np.mean(coefs, axis=0)\n",
        "        avg_intercept = np.mean(intercepts, axis=0)\n",
        "\n",
        "        avg_model.coef_ = avg_coef\n",
        "        avg_model.intercept_ = avg_intercept\n",
        "        avg_model.classes_ = models[0].classes_\n",
        "\n",
        "        return avg_model\n",
        "\n",
        "    local_avg_model = average_sgd_models(local_models)\n",
        "    local_avg_metrics = evaluate_model(local_avg_model, X_new_scaled, y_new)\n",
        "\n",
        "\n",
        "    central_model = SGDClassifier(\n",
        "        loss=\"log_loss\", max_iter=200, tol=None,\n",
        "        warm_start=True, learning_rate=\"optimal\", eta0=0.01\n",
        "    )\n",
        "    train_model(central_model, X_train_scaled_central, y_train)\n",
        "    central_metrics = evaluate_model(central_model, X_new_scaled, y_new)\n",
        "\n",
        "    all_results = [\n",
        "        {\"mode\": \"federated\", **final_fl_metrics},\n",
        "        {\"mode\": \"personalized_federated\", **personalized_metrics},\n",
        "        {\"mode\": \"local\", **local_metrics},\n",
        "        {\"mode\": \"local_avg\", **local_avg_metrics},\n",
        "        {\"mode\": \"centralized\", **central_metrics},\n",
        "    ]\n",
        "\n",
        "    for result in all_results:\n",
        "        mode = result[\"mode\"]\n",
        "        results[mode].append(result)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "summary_rows = []\n",
        "for mode, metrics_list in results.items():\n",
        "    df_mode = pd.DataFrame(metrics_list)\n",
        "    row = {\"mode\": mode}\n",
        "    for metric in df_mode.columns:\n",
        "        if metric == \"mode\":\n",
        "            continue\n",
        "        row[f\"{metric}_mean\"] = df_mode[metric].mean()\n",
        "        row[f\"{metric}_std\"] = df_mode[metric].std()\n",
        "    summary_rows.append(row)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(f\"results_20cv_basis{basisnum}_LR.csv\", index=False)\n",
        "print(summary_df)\n",
        "\n",
        "# Save all results\n",
        "all_results_by_basis[basisnum] = results.copy()\n",
        "\n",
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "fold = 0"
      ],
      "metadata": {
        "id": "uSuqc-DOJwmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Model Accuracy Across Modes for LR\n",
        "This code aggregates accuracy across all cross-validation folds and model types, then visualizes the results.\n",
        "\n",
        "- Collects accuracy scores from all modes and basis numbers into a DataFrame.\n",
        "- Saves the results as LR_accuracies.csv.\n",
        "- Plots a boxplot of accuracy by mode (e.g., federated, local, centralized) using Seaborn to compare performance distributions.  \n",
        "\n",
        "This allows easy comparison of how each model type performs across different data splits and experiments."
      ],
      "metadata": {
        "id": "vPW6yasbWtrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = []\n",
        "for basisnum, mode_results in all_results_by_basis.items():\n",
        "    for mode, metrics_list in mode_results.items():\n",
        "        for fold_metrics in metrics_list:\n",
        "            df_all.append({\n",
        "                \"basis\": basisnum,\n",
        "                \"mode\": mode,\n",
        "                \"accuracy\": fold_metrics[\"accuracy\"]\n",
        "            })\n",
        "\n",
        "df_plot = pd.DataFrame(df_all)\n",
        "df_plot.to_csv(\"LR_accuracies.csv\", index=False)\n",
        "print(df_plot)\n",
        "\n",
        "# Plot accuracy distribution by mode\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_plot, x=\"mode\", y=\"accuracy\", hue=\"mode\", palette=\"Set3\")\n",
        "plt.title(\"Accuracy Distribution Across Folds by Mode (LR)\")\n",
        "plt.xlabel(\"Mode\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"accuracy_boxplot_by_mode_LR.png\", dpi=600)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zXzHtedZJyLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Support Vector Machine Setup\n",
        "\n",
        "This code sets up a basic federated learning workflow using the Flower library and scikit-learn's SGDClassifier (hinge loss).\n",
        "\n",
        "Parameter management: Functions get, set, and average the model's weights across different clients.  \n",
        "Model utilities: Functions for incremental training (partial_fit) and evaluating with standard metrics (loss, accuracy, precision, recall, F1).  \n",
        "FlowerClient: Each client handles its own data partition, receives and updates model parameters, trains locally, and reports metrics.  \n",
        "Server functions: Aggregate client metrics, perform federated averaging, and orchestrate rounds.  \n",
        "Configuration: Specifies number of rounds and system resources for clients."
      ],
      "metadata": {
        "id": "MnzA2NbDXDvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(model):\n",
        "    return [model.coef_.copy(), model.intercept_.copy()]\n",
        "\n",
        "def set_parameters(model, parameters):\n",
        "    model.coef_ = parameters[0].copy()\n",
        "    model.intercept_ = parameters[1].copy()\n",
        "\n",
        "def average_parameters(parameter_list):\n",
        "    avg_coef = np.mean([params[0] for params in parameter_list], axis=0)\n",
        "    avg_intercept = np.mean([params[1] for params in parameter_list], axis=0)\n",
        "    return [avg_coef, avg_intercept]\n",
        "\n",
        "def train_model(model, X, y):\n",
        "    if not hasattr(model, \"coef_\"):\n",
        "        model.partial_fit(X, y, classes=np.array([0,1]))\n",
        "    else:\n",
        "        model.partial_fit(X, y)\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    preds = model.predict(X)\n",
        "    decision_fn = model.decision_function(X)\n",
        "    return {\n",
        "        \"loss\": hinge_loss(y, decision_fn, labels=model.classes_),\n",
        "        \"accuracy\": accuracy_score(y, preds),\n",
        "        \"precision\": precision_score(y, preds, average=\"binary\", zero_division=0),\n",
        "        \"recall\": recall_score(y, preds, average=\"binary\", zero_division=0),\n",
        "        \"f1\": f1_score(y, preds, average=\"binary\", zero_division=0),\n",
        "    }\n",
        "def initialize_model(n_features):\n",
        "    model = SGDClassifier(\n",
        "        loss=\"hinge\",\n",
        "        max_iter=20,\n",
        "        tol=None,\n",
        "        warm_start=True,\n",
        "        learning_rate=\"optimal\",\n",
        "        eta0=0.01,\n",
        "        random_state=42,\n",
        "    )\n",
        "    return model\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id: int, personalized=False):\n",
        "        self.partition_id = partition_id\n",
        "        self.model = initialize_model(X_train_full.shape[1])\n",
        "        self.X_train, self.y_train = client_train_data[partition_id]\n",
        "        self.X_val, self.y_val = client_val_data[partition_id]\n",
        "        self.personalized = personalized\n",
        "        self.model.partial_fit(self.X_train, self.y_train, classes=np.array([0, 1]))\n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        train_model(self.model, self.X_train, self.y_train)\n",
        "        return get_parameters(self.model), len(self.X_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        metrics = evaluate_model(self.model, self.X_val, self.y_val)\n",
        "        loss = metrics.pop(\"loss\", 0.0)\n",
        "        return loss, len(self.y_val), metrics\n",
        "\n",
        "final_fl_metrics = None\n",
        "final_parameters = None\n",
        "\n",
        "def get_evaluate_fn():\n",
        "    def evaluate(server_round, parameters, config):\n",
        "        all_metrics = []\n",
        "        for cid in range(NUM_PARTITIONS):\n",
        "            model = initialize_model(X_train_full.shape[1])\n",
        "            X_val, y_val = client_val_data[cid]\n",
        "            set_parameters(model, parameters)\n",
        "            model.classes_ = np.unique(y_train_full)\n",
        "            metrics = evaluate_model(model, X_val, y_val)\n",
        "            all_metrics.append(metrics)\n",
        "\n",
        "        df_metrics = pd.DataFrame(all_metrics)\n",
        "        avg_metrics = df_metrics.mean().to_dict()\n",
        "\n",
        "        if server_round == 10:\n",
        "            global final_fl_metrics, final_parameters\n",
        "            final_fl_metrics = avg_metrics.copy()\n",
        "            final_parameters = parameters\n",
        "\n",
        "        return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "    return evaluate\n",
        "\n",
        "def server_fn(context):\n",
        "    strategy = FedAvg(\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        evaluate_fn=get_evaluate_fn(),\n",
        "        fit_metrics_aggregation_fn=None,\n",
        "        evaluate_metrics_aggregation_fn=None\n",
        "    )\n",
        "    return ServerAppComponents(config=ServerConfig(num_rounds=10), strategy=strategy)\n",
        "\n",
        "def client_fn(context):\n",
        "    cid = context.node_config.get(\"partition-id\", 0)\n",
        "    return FlowerClient(cid).to_client()\n",
        "\n",
        "client = ClientApp(client_fn=client_fn)\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 0}}"
      ],
      "metadata": {
        "id": "E_HaGd_aKdK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross-Validation Evaluation of Federated and Baseline Models for SVM\n",
        "This script runs repeated train/test splits to compare federated, personalized, local, and centralized models.\n",
        "\n",
        "- For each fold, the data is split into training, testing, and personalized subsets with stratification.\n",
        "- Each partition is preprocessed and used to prepare client data.\n",
        "- A federated simulation runs, aggregating client models.\n",
        "- Evaluations are performed for:\n",
        "federated learning (global model),\n",
        "personalized federated (fine-tuned global model),\n",
        "local-only models (trained on each client),\n",
        "averaged local models (ensemble of locals),\n",
        "and a centralized model (trained on pooled data).\n",
        "- All results and summary statistics are saved for further analysis."
      ],
      "metadata": {
        "id": "FfFcJAOdXgvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "\n",
        "all_results_by_basis = {}\n",
        "fold = 0\n",
        "\n",
        "print(f\"--- Basis {basisnum} ---\")\n",
        "for repeat in range(NUM_FOLDS):\n",
        "    print(f\"--- Fold {repeat + 1}/{NUM_FOLDS} ---\")\n",
        "    # Combined data splitting\n",
        "    X_rest, X_new, y_rest, y_new = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, shuffle=True, random_state=repeat)\n",
        "\n",
        "    X_train_personal_raw, X_test_personal_raw, y_train_personal, y_test_personal = train_test_split(\n",
        "        X_new, y_new, test_size=0.2, stratify=y_new, random_state=42)\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X_rest, y_rest, test_size=0.2, stratify=y_rest, shuffle=True, random_state=repeat)\n",
        "\n",
        "    # Preprocessing for central and new data\n",
        "    X_train_scaled_central, scaler_central = preprocess_data(X_train_raw)\n",
        "    X_test_scaled_central, _ = preprocess_data(X_test_raw, scaler=scaler_central)\n",
        "    X_new_scaled, _ = preprocess_data(X_new)\n",
        "\n",
        "    # Apply same preprocessing to personalized data\n",
        "    X_train_personal_scaled, personal_scaler = preprocess_data(X_train_personal_raw)\n",
        "    X_test_personal_scaled, _ = preprocess_data(X_test_personal_raw, scaler=personal_scaler)\n",
        "\n",
        "    X_train_partitions_raw = np.array_split(X_train_raw, NUM_PARTITIONS)\n",
        "    y_train_partitions = np.array_split(y_train, NUM_PARTITIONS)\n",
        "    X_test_partitions_raw = np.array_split(X_test_raw, NUM_PARTITIONS)\n",
        "    y_test_partitions = np.array_split(y_test, NUM_PARTITIONS)\n",
        "    client_train_data = {}\n",
        "    client_val_data = {}\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        X_train_reduced = fit_bspline_basis(X_train_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
        "\n",
        "        X_test_reduced = fit_bspline_basis(X_test_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        X_test_scaled = scaler.transform(X_test_reduced)\n",
        "\n",
        "        client_train_data[cid] = (X_train_scaled, y_train_partitions[cid])\n",
        "        client_val_data[cid] = (X_test_scaled, y_test_partitions[cid])\n",
        "\n",
        "    run_simulation(\n",
        "        server_app=server,\n",
        "        client_app=client,\n",
        "        num_supernodes=NUM_PARTITIONS,\n",
        "        backend_config=backend_config\n",
        "    )\n",
        "\n",
        "    model = initialize_model(X_new_scaled.shape[1])\n",
        "    set_parameters(model, final_parameters)\n",
        "    model.classes_ = np.unique(y_new)\n",
        "    final_fl_metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "\n",
        "    def run_personalized_evaluation(final_parameters):\n",
        "        model = initialize_model(X_train_personal_scaled.shape[1])\n",
        "        set_parameters(model, final_parameters)\n",
        "        # Train on train split\n",
        "        model.partial_fit(X_train_personal_scaled, y_train_personal, classes=np.unique(y))\n",
        "        # Evaluate on test split\n",
        "        metrics = evaluate_model(model, X_test_personal_scaled, y_test_personal)\n",
        "        return metrics\n",
        "\n",
        "    personalized_metrics = run_personalized_evaluation(final_parameters)\n",
        "\n",
        "    local_metrics_list = []\n",
        "    local_models = []\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        model = SGDClassifier(\n",
        "            loss=\"hinge\", max_iter=200, tol=None,\n",
        "            warm_start=True, learning_rate=\"optimal\", eta0=0.01\n",
        "        )\n",
        "        X_train_client, y_train_client = client_train_data[cid]\n",
        "        # Train local model on client data\n",
        "        train_model(model, X_train_client, y_train_client)\n",
        "        local_models.append(model)\n",
        "        # Evaluate local model on the common new data\n",
        "        metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "        local_metrics_list.append(metrics)\n",
        "\n",
        "    # Average metrics from local models evaluated on X_new_scaled\n",
        "    local_metrics = pd.DataFrame(local_metrics_list).mean().to_dict()\n",
        "\n",
        "    # Now average the local models' weights\n",
        "    def average_sgd_models(models):\n",
        "        # This assumes sklearn SGDClassifier, average coef_ and intercept_\n",
        "        avg_model = initialize_model(X_new_scaled.shape[1])\n",
        "\n",
        "        coefs = np.array([m.coef_ for m in models])\n",
        "        intercepts = np.array([m.intercept_ for m in models])\n",
        "\n",
        "        avg_coef = np.mean(coefs, axis=0)\n",
        "        avg_intercept = np.mean(intercepts, axis=0)\n",
        "\n",
        "        avg_model.coef_ = avg_coef\n",
        "        avg_model.intercept_ = avg_intercept\n",
        "        avg_model.classes_ = models[0].classes_\n",
        "\n",
        "        return avg_model\n",
        "\n",
        "    local_avg_model = average_sgd_models(local_models)\n",
        "    local_avg_metrics = evaluate_model(local_avg_model, X_new_scaled, y_new)\n",
        "\n",
        "\n",
        "    central_model = SGDClassifier(\n",
        "        loss=\"hinge\", max_iter=200, tol=None,\n",
        "        warm_start=True, learning_rate=\"optimal\", eta0=0.01\n",
        "    )\n",
        "    train_model(central_model, X_train_scaled_central, y_train)\n",
        "    central_metrics = evaluate_model(central_model, X_new_scaled, y_new)\n",
        "\n",
        "    all_results = [\n",
        "        {\"mode\": \"federated\", **final_fl_metrics},\n",
        "        {\"mode\": \"personalized_federated\", **personalized_metrics},\n",
        "        {\"mode\": \"local\", **local_metrics},\n",
        "        {\"mode\": \"local_avg\", **local_avg_metrics},\n",
        "        {\"mode\": \"centralized\", **central_metrics},\n",
        "    ]\n",
        "\n",
        "    for result in all_results:\n",
        "        mode = result[\"mode\"]\n",
        "        results[mode].append(result)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "summary_rows = []\n",
        "for mode, metrics_list in results.items():\n",
        "    df_mode = pd.DataFrame(metrics_list)\n",
        "    row = {\"mode\": mode}\n",
        "    for metric in df_mode.columns:\n",
        "        if metric == \"mode\":\n",
        "            continue\n",
        "        row[f\"{metric}_mean\"] = df_mode[metric].mean()\n",
        "        row[f\"{metric}_std\"] = df_mode[metric].std()\n",
        "    summary_rows.append(row)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(f\"results_20cv_basis{basisnum}_SVM.csv\", index=False)\n",
        "print(summary_df)\n",
        "\n",
        "# Save all results\n",
        "all_results_by_basis[basisnum] = results.copy()\n",
        "\n",
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "fold = 0"
      ],
      "metadata": {
        "id": "H7P5Tq9kKfL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Model Accuracy Across Modes for SVM\n",
        "This code aggregates accuracy across all cross-validation folds and model types, then visualizes the results.\n",
        "\n",
        "- Collects accuracy scores from all modes and basis numbers into a DataFrame.\n",
        "- Saves the results as SVM_accuracies.csv.\n",
        "- Plots a boxplot of accuracy by mode (e.g., federated, local, centralized) using Seaborn to compare performance distributions.  \n",
        "\n",
        "This allows easy comparison of how each model type performs across different data splits and experiments."
      ],
      "metadata": {
        "id": "Af_ZDfMMW8qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = []\n",
        "for basisnum, mode_results in all_results_by_basis.items():\n",
        "    for mode, metrics_list in mode_results.items():\n",
        "        for fold_metrics in metrics_list:\n",
        "            df_all.append({\n",
        "                \"basis\": basisnum,\n",
        "                \"mode\": mode,\n",
        "                \"accuracy\": fold_metrics[\"accuracy\"]\n",
        "            })\n",
        "\n",
        "df_plot = pd.DataFrame(df_all)\n",
        "df_plot.to_csv(\"SVM_accuracies.csv\", index=False)\n",
        "print(df_plot)\n",
        "\n",
        "# Plot accuracy distribution by mode\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_plot, x=\"mode\", y=\"accuracy\", hue=\"mode\", palette=\"Set3\")\n",
        "plt.title(\"Accuracy Distribution Across Folds by Mode (SVM)\")\n",
        "plt.xlabel(\"Mode\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"accuracy_boxplot_by_mode_SVM.png\", dpi=600)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ngTiev_ZK1tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Federated Learning Setup\n",
        "\n",
        "This code sets up a federated learning workflow using the Flower library and a simple PyTorch neural network.\n",
        "\n",
        "Model architecture: Defines a feedforward neural network with two hidden layers, batch normalization, dropout, and ReLU activations.  \n",
        "Parameter management: Functions to get and set model weights as numpy arrays for communication between clients and server.  \n",
        "Model utilities: Training uses Adam optimizer and cross-entropy loss; evaluation computes accuracy, precision, recall, and F1.  \n",
        "FlowerClient: Each client manages its own data, updates its neural network, and shares metrics after local training.  \n",
        "Server functions: Aggregate client metrics, perform federated averaging, orchestrate training rounds, and save final parameters."
      ],
      "metadata": {
        "id": "daPu7bmlXOYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def get_parameters(model):\n",
        "    return [val.cpu().numpy() for val in model.state_dict().values()]\n",
        "\n",
        "def set_parameters(model, parameters):\n",
        "    state_dict = model.state_dict()\n",
        "    for k, v in zip(state_dict.keys(), parameters):\n",
        "        state_dict[k] = torch.tensor(v)\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "def train_model(model, X, y, epochs=15):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
        "    for _ in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_tensor)\n",
        "        loss = criterion(outputs, y_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "    y_tensor = torch.tensor(y, dtype=torch.long).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(X_tensor)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        loss = nn.CrossEntropyLoss()(logits, y_tensor).item()\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"accuracy\": accuracy_score(y, preds.cpu().numpy()),\n",
        "        \"precision\": precision_score(y, preds.cpu().numpy(), average=\"binary\", zero_division=0),\n",
        "        \"recall\": recall_score(y, preds.cpu().numpy(), average=\"binary\", zero_division=0),\n",
        "        \"f1\": f1_score(y, preds.cpu().numpy(), average=\"binary\", zero_division=0)\n",
        "    }\n",
        "\n",
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, partition_id: int, personalized=False):\n",
        "        self.partition_id = partition_id\n",
        "        self.model = SimpleNN(input_size=client_train_data[partition_id][0].shape[1])\n",
        "        self.X_train, self.y_train = client_train_data[partition_id]\n",
        "        self.X_val, self.y_val = client_val_data[partition_id]\n",
        "        self.personalized = personalized\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        train_model(self.model, self.X_train, self.y_train, epochs=15)\n",
        "        return get_parameters(self.model), len(self.X_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.model, parameters)\n",
        "        X_val, y_val = client_val_data[self.partition_id]\n",
        "        metrics = evaluate_model(self.model, X_val, y_val)\n",
        "        loss = metrics.pop(\"loss\")\n",
        "        return loss, len(y_val), metrics\n",
        "\n",
        "final_metrics = {}\n",
        "final_fl_metrics = None\n",
        "final_parameters = None\n",
        "\n",
        "def get_evaluate_fn():\n",
        "    def evaluate(server_round, parameters, config):\n",
        "        all_metrics = []\n",
        "        for cid in range(NUM_PARTITIONS):\n",
        "            model = SimpleNN(input_size=client_val_data[cid][0].shape[1])\n",
        "            X_val, y_val = client_val_data[cid]\n",
        "            set_parameters(model, parameters)\n",
        "            metrics = evaluate_model(model, X_val, y_val)\n",
        "            all_metrics.append(metrics)\n",
        "\n",
        "        avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n",
        "\n",
        "        if server_round == 10:  # final round\n",
        "            global final_fl_metrics, final_parameters\n",
        "            final_fl_metrics = avg_metrics.copy()\n",
        "            final_parameters = parameters\n",
        "\n",
        "        return avg_metrics[\"loss\"], {\"accuracy\": avg_metrics[\"accuracy\"]}\n",
        "    return evaluate\n",
        "\n",
        "def server_fn(context):\n",
        "    strategy = FedAvg(\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        evaluate_fn=get_evaluate_fn(),\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=10)\n",
        "    return ServerAppComponents(config=config, strategy=strategy)\n",
        "\n",
        "# === Client Factory ===\n",
        "def client_fn(context):\n",
        "    partition_id = context.node_config.get(\"partition-id\", 0)\n",
        "    return FlowerClient(partition_id).to_client()\n",
        "\n",
        "client = ClientApp(client_fn=client_fn)\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 2, \"num_gpus\": 1}}"
      ],
      "metadata": {
        "id": "aKTi8u-WK_O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cross-Validation Evaluation of Federated and Baseline Models for NN\n",
        "This script runs repeated train/test splits to compare federated, personalized, local, and centralized models.\n",
        "\n",
        "- For each fold, the data is split into training, testing, and personalized subsets with stratification.\n",
        "- Each partition is preprocessed and used to prepare client data.\n",
        "- A federated simulation runs, aggregating client models.\n",
        "- Evaluations are performed for:\n",
        "federated learning (global model),\n",
        "personalized federated (fine-tuned global model),\n",
        "local-only models (trained on each client),\n",
        "averaged local models (ensemble of locals),\n",
        "and a centralized model (trained on pooled data).\n",
        "- All results and summary statistics are saved for further analysis."
      ],
      "metadata": {
        "id": "wvYtZQFDXjWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "\n",
        "basisnum = 10\n",
        "\n",
        "all_results_by_basis = {}\n",
        "fold = 0\n",
        "\n",
        "print(f\"--- Basis {basisnum} ---\")\n",
        "for repeat in range(NUM_FOLDS):\n",
        "    print(f\"--- Fold {repeat + 1}/{NUM_FOLDS} ---\")\n",
        "    # Combined data splitting\n",
        "    X_rest, X_new, y_rest, y_new = train_test_split(\n",
        "        X, y, test_size=0.2, stratify=y, shuffle=True, random_state=repeat)\n",
        "\n",
        "    X_train_personal_raw, X_test_personal_raw, y_train_personal, y_test_personal = train_test_split(\n",
        "        X_new, y_new, test_size=0.2, stratify=y_new, random_state=42)\n",
        "\n",
        "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "        X_rest, y_rest, test_size=0.2, stratify=y_rest, shuffle=True, random_state=repeat)\n",
        "\n",
        "    # Preprocessing for central and new data\n",
        "    X_train_scaled_central, scaler_central = preprocess_data(X_train_raw)\n",
        "    X_test_scaled_central, _ = preprocess_data(X_test_raw, scaler=scaler_central)\n",
        "    X_new_scaled, _ = preprocess_data(X_new)\n",
        "\n",
        "    # Apply same preprocessing to personalized data\n",
        "    X_train_personal_scaled, personal_scaler = preprocess_data(X_train_personal_raw)\n",
        "    X_test_personal_scaled, _ = preprocess_data(X_test_personal_raw, scaler=personal_scaler)\n",
        "\n",
        "    X_train_partitions_raw = np.array_split(X_train_raw, NUM_PARTITIONS)\n",
        "    y_train_partitions = np.array_split(y_train, NUM_PARTITIONS)\n",
        "    X_test_partitions_raw = np.array_split(X_test_raw, NUM_PARTITIONS)\n",
        "    y_test_partitions = np.array_split(y_test, NUM_PARTITIONS)\n",
        "    client_train_data = {}\n",
        "    client_val_data = {}\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        X_train_reduced = fit_bspline_basis(X_train_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
        "\n",
        "        X_test_reduced = fit_bspline_basis(X_test_partitions_raw[cid], num_basis=basisnum, spline_order=3)\n",
        "        X_test_scaled = scaler.transform(X_test_reduced)\n",
        "\n",
        "        client_train_data[cid] = (X_train_scaled, y_train_partitions[cid])\n",
        "        client_val_data[cid] = (X_test_scaled, y_test_partitions[cid])\n",
        "\n",
        "    run_simulation(\n",
        "        server_app=server,\n",
        "        client_app=client,\n",
        "        num_supernodes=NUM_PARTITIONS,\n",
        "        backend_config=backend_config\n",
        "    )\n",
        "\n",
        "    model = SimpleNN(input_size=X_new_scaled.shape[1])\n",
        "    set_parameters(model, final_parameters)\n",
        "    final_fl_metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "\n",
        "    def run_personalized_evaluation(final_parameters):\n",
        "        model = SimpleNN(input_size=X_new_scaled.shape[1])\n",
        "        set_parameters(model, final_parameters)\n",
        "\n",
        "        train_model(model, X_train_personal_scaled, y_train_personal, epochs=15)\n",
        "        metrics = evaluate_model(model, X_test_personal_scaled, y_test_personal)\n",
        "        return metrics\n",
        "\n",
        "    personalized_metrics = run_personalized_evaluation(final_parameters)\n",
        "\n",
        "    local_models = []\n",
        "    local_metrics_list = []\n",
        "\n",
        "    for cid in range(NUM_PARTITIONS):\n",
        "        X_train_client, y_train_client = client_train_data[cid]\n",
        "        model = SimpleNN(input_size=X_train_client.shape[1])\n",
        "        train_model(model, X_train_client, y_train_client, epochs=150)\n",
        "\n",
        "        local_models.append(model)\n",
        "\n",
        "        metrics = evaluate_model(model, X_new_scaled, y_new)\n",
        "        local_metrics_list.append(metrics)\n",
        "\n",
        "    local_metrics = pd.DataFrame(local_metrics_list).mean().to_dict()\n",
        "\n",
        "    def average_nn_models(models):\n",
        "        avg_model = SimpleNN(input_size=X_new_scaled.shape[1])\n",
        "\n",
        "        state_dicts = [m.state_dict() for m in models]\n",
        "        avg_state_dict = {}\n",
        "\n",
        "        for key in state_dicts[0]:\n",
        "            avg_state_dict[key] = sum(d[key] for d in state_dicts) / len(state_dicts)\n",
        "\n",
        "        avg_model.load_state_dict(avg_state_dict)\n",
        "        return avg_model\n",
        "\n",
        "    local_avg_model = average_nn_models(local_models)\n",
        "    local_avg_metrics = evaluate_model(local_avg_model, X_new_scaled, y_new)\n",
        "\n",
        "    central_model = SimpleNN(input_size=X_train_scaled_central.shape[1])\n",
        "    train_model(central_model, X_train_scaled_central, y_train, epochs=150)\n",
        "    central_metrics = evaluate_model(central_model, X_new_scaled, y_new)\n",
        "\n",
        "    all_results = [\n",
        "        {\"mode\": \"federated\", **final_fl_metrics},\n",
        "        {\"mode\": \"personalized_federated\", **personalized_metrics},\n",
        "        {\"mode\": \"local\", **local_metrics},\n",
        "        {\"mode\": \"local_avg\", **local_avg_metrics},\n",
        "        {\"mode\": \"centralized\", **central_metrics},\n",
        "    ]\n",
        "\n",
        "    for result in all_results:\n",
        "        mode = result[\"mode\"]\n",
        "        results[mode].append(result)\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "summary_rows = []\n",
        "for mode, metrics_list in results.items():\n",
        "    df_mode = pd.DataFrame(metrics_list)\n",
        "    row = {\"mode\": mode}\n",
        "    for metric in df_mode.columns:\n",
        "        if metric == \"mode\":\n",
        "            continue\n",
        "        row[f\"{metric}_mean\"] = df_mode[metric].mean()\n",
        "        row[f\"{metric}_std\"] = df_mode[metric].std()\n",
        "    summary_rows.append(row)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df.to_csv(f\"results_20cv_basis{basisnum}_NN.csv\", index=False)\n",
        "print(summary_df)\n",
        "\n",
        "# Save all results\n",
        "all_results_by_basis[basisnum] = results.copy()\n",
        "\n",
        "results = {\n",
        "    \"federated\": [],\n",
        "    \"personalized_federated\": [],\n",
        "    \"local\": [],\n",
        "    \"local_avg\": [],\n",
        "    \"centralized\": []\n",
        "}\n",
        "fold = 0"
      ],
      "metadata": {
        "id": "4eANebosLPA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing Model Accuracy Across Modes for NN\n",
        "This code aggregates accuracy across all cross-validation folds and model types, then visualizes the results.\n",
        "\n",
        "- Collects accuracy scores from all modes and basis numbers into a DataFrame.\n",
        "- Saves the results as NN_accuracies.csv.\n",
        "- Plots a boxplot of accuracy by mode (e.g., federated, local, centralized) using Seaborn to compare performance distributions.  \n",
        "\n",
        "This allows easy comparison of how each model type performs across different data splits and experiments."
      ],
      "metadata": {
        "id": "C5buzj6_W41I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = []\n",
        "for basisnum, mode_results in all_results_by_basis.items():\n",
        "    for mode, metrics_list in mode_results.items():\n",
        "        for fold_metrics in metrics_list:\n",
        "            df_all.append({\n",
        "                \"basis\": basisnum,\n",
        "                \"mode\": mode,\n",
        "                \"accuracy\": fold_metrics[\"accuracy\"]\n",
        "            })\n",
        "\n",
        "df_plot = pd.DataFrame(df_all)\n",
        "df_plot.to_csv(\"NN_accuracies.csv\", index=False)\n",
        "print(df_plot)\n",
        "\n",
        "# Plot accuracy distribution by mode\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_plot, x=\"mode\", y=\"accuracy\", hue=\"mode\", palette=\"Set3\")\n",
        "plt.title(\"Accuracy Distribution Across Folds by Mode (NN)\")\n",
        "plt.xlabel(\"Mode\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"accuracy_boxplot_by_mode_NN.png\", dpi=600)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y6w9FyUgLUE8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}